{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc41b896",
   "metadata": {},
   "source": [
    "# Rule based Chatbot-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "root = Tk()\n",
    "root.title(\"shaheel-Chatbot\")\n",
    "def send():\n",
    "    send = \"You -> \"+e.get()\n",
    "    txt.insert(END, \" \"+send)\n",
    "    user = e.get().lower()\n",
    "    if(user == \"hello\"):\n",
    "        txt.insert(END, \"\\n shaheel\" + \"Robo -> Hi  \")\n",
    "    elif(user == \"hi\" or user == \"hii\" or user == \"hiiii\"):\n",
    "        txt.insert(END, \"\\n shaheel\" + \"Robo -> Hello  \")\n",
    "    elif(e.get() == \"how are you  \"):\n",
    "        txt.insert(END, \"\\n shaheel\" + \"Robo -> fine! and you  \")\n",
    "    elif(user == \"fine\" or user == \"i am good\" or user == \"i am doing good  \"):\n",
    "        txt.insert(END, \"\\n shaheel\" + \"Robo -> Great! how can I help you.  \")\n",
    "    else:\n",
    "        txt.insert(END, \"\\n shaheel\" + \"Robo -> Sorry! I dind't got you  \")\n",
    "    e.delete(0, END)\n",
    "txt = Text(root)\n",
    "txt.grid(row=0, column=0, columnspan=2)\n",
    "e = Entry(root, width=100)\n",
    "e.grid(row=1, column=0)\n",
    "send = Button(root, text=\"Send\", command=send).grid(row=1, column=1)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e86012",
   "metadata": {},
   "source": [
    "# Rule based Chatbot-2 \n",
    "### Extracting TF-IDF features and reading data from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d3fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53675eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(r'C:\\Users\\Win 10\\Downloads\\Chatbot.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw = raw.lower()# converts to lowercase\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences\n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badde57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what’s up\",\"hey\",\"yo\")\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f100348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    spar_response=\"\"\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        spar_response=spar_response+\"I don’t understand you\"\n",
    "        return spar_response\n",
    "    else:\n",
    "        spar_response = spar_response+sent_tokens[idx]\n",
    "        return spar_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb30cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=True\n",
    "print(\"shaheel-Bot: My name is Muhammed shaheel-Bot. I will answer your queries about Chatbots. If you want to quit, type Bye! \")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you '):\n",
    "            flag=False\n",
    "            print(\"shaheel-Bot: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"shaheel-Bot: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"shaheel-Bot:\" ,end=\" \")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba5f88",
   "metadata": {},
   "source": [
    "# Using Reflections Chatbot-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflections = {\n",
    "  \"i am\"       : \"you are\",\n",
    "  \"i was\"      : \"you were\",\n",
    "  \"i\"          : \"you\",\n",
    "  \"i'm\"        : \"you are\",\n",
    "  \"i'd\"        : \"you would\",\n",
    "  \"i've\"       : \"you have\",\n",
    "  \"i'll\"       : \"you will\",\n",
    "  \"my\"         : \"your\",\n",
    "  \"you are\"    : \"I am\",\n",
    "  \"you were\"   : \"I was\",\n",
    "  \"you've\"     : \"I have\",\n",
    "  \"you'll\"     : \"I will\",\n",
    "  \"your\"       : \"my\",\n",
    "  \"yours\"      : \"mine\",\n",
    "  \"you\"        : \"me\",\n",
    "  \"me\"         : \"you\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    [\n",
    "        r\"my name is (.*)\",\n",
    "        [\"Hello %1, How are you today ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"hi|hey|hello\",\n",
    "        [\"Hello\", \"Hey there\",]\n",
    "    ], \n",
    "    [\n",
    "        r\"what is your name ?\",\n",
    "        [\"I am a bot created by shaheel Solutions Private Limited. you can call me crazy!\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"how are you ?\",\n",
    "        [\"I'm doing goodnHow about You ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"sorry (.*)\",\n",
    "        [\"Its alright\",\"Its OK, never mind\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"I am fine\",\n",
    "        [\"Great to hear that, How can I help you?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"i'm (.*) doing good\",\n",
    "        [\"Nice to hear that\",\"How can I help you?:)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) age?\",\n",
    "        [\"I'm a computer program dude n Seriously you are asking me this?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"what (.*) want ?\",\n",
    "        [\"Make me an offer I can't refuse\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) created ?\",\n",
    "        [\"Rose created me using Python's NLTK library \",\"top secret ;)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (location|city) ?\",\n",
    "        ['Bangalore, Karnataka',]\n",
    "    ],\n",
    "    [\n",
    "        r\"how is weather in (.*)?\",\n",
    "        [\"Weather in %1 is awesome like always\",\"Too hot man here in %1\",\"Too cold man here in %1\",\"Never even heard about %1\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i work in (.*)?\",\n",
    "        [\"%1 is an Amazing company, I have heard about it. But they are in huge loss these days.\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*)raining in (.*)\",\n",
    "        [\"No rain since last week here in %2\",\"Damn its raining too much here in %2\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"how (.*) health(.*)\",\n",
    "        [\"I'm a computer program, so I'm always healthy \",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (sports|game) ?\",\n",
    "        [\"I'm a very big fan of Football\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) sportsperson ?\",\n",
    "        [\"Messy\",\"Ronaldo\",\"Roony\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) (moviestar|actor)?\",\n",
    "        [\"Brad Pitt\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i am looking for online guides and courses to learn Pychology, can you suggest?\",\n",
    "        [\"iPEC_Solutions has many great articles with each step explanation along with code, you can explore\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"quit\",\n",
    "        [\"BBye take care. See you soon :) \",\"It was nice talking to you. See you soon :)\"]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153286eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Hi! I am a chatbot created by Muhammed shaheel\")\n",
    "    chat = Chat(pairs, reflections)\n",
    "    chat.converse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96202571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the conversation\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45557f77",
   "metadata": {},
   "source": [
    "# 4. Chatbot using Deep Learning\n",
    "tensorflow==2.3.1 </br>\n",
    "nltk==3.5</br>\n",
    "colorama==0.4.3</br>\n",
    "numpy==1.18.5</br>\n",
    "scikit_learn==0.23.2</br>\n",
    "Flask==1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e08590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0eca5b",
   "metadata": {},
   "source": [
    "#### Step 1: Data Creation and save as json file format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d792be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data and save as json file format\n",
    "J={\"intents\": [\n",
    "    {\"tag\": \"greeting\",\n",
    "     \"patterns\": [\"Hi\", \"Hey\", \"Is anyone there?\", \"Hello\", \"Hay\"],\n",
    "     \"responses\": [\"Hello\", \"Hi\", \"Hi there\"]\n",
    "    },\n",
    "    {\"tag\": \"goodbye\",\n",
    "     \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
    "     \"responses\": [\"See you later\", \"Have a nice day\", \"Bye! Come back again\"]\n",
    "    },\n",
    "    {\"tag\": \"thanks\",\n",
    "     \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thanks for the help\"],\n",
    "     \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\", \"You're most welcome!\"]\n",
    "    },\n",
    "    {\"tag\": \"about\",\n",
    "     \"patterns\": [\"Who are you?\", \"What are you?\", \"Who you are?\" ],\n",
    "     \"responses\": [\"I.m shaheel Assistant, your personal assistant\", \"I'm shaheel Assistant, an Artificial Intelligent bot\"]\n",
    "    },\n",
    "    {\"tag\": \"name\",\n",
    "    \"patterns\": [\"what is your name\", \"what should I call you\", \"whats your name?\"],\n",
    "    \"responses\": [\"You can call me Darling.\", \"I'm shaheelAssistant!\", \"Just call me as Babby\"]\n",
    "    },\n",
    "    {\"tag\": \"help\",\n",
    "    \"patterns\": [\"Could you help me?\", \"give me a hand please\", \"Can you help?\", \"What can you do for me?\", \"I need a support\", \"I need a help\", \"support me please\"],\n",
    "    \"responses\": [\"Tell me how can assist you\", \"Tell me your problem to assist you\", \"Yes Sure, How can I support you\"]\n",
    "    },\n",
    "    {\"tag\": \"createaccount\",\n",
    "    \"patterns\": [\"I need to create a new account\", \"how to open a new account\", \"I want to create an account\", \"can you create an account for me\", \"how to open a new account\"],\n",
    "    \"responses\": [\"You can just easily create a new account from our web site\", \"Just go to our web site and follow the guidelines to create a new account\"]\n",
    "    },\n",
    "    {\"tag\": \"complaint\",\n",
    "    \"patterns\": [\"have a complaint\", \"I want to raise a complaint\", \"there is a complaint about a service\"],\n",
    "    \"responses\": [\"Please provide us your complaint in order to assist you\", \"Please mention your complaint, we will reach you and sorry for any inconvenience caused\"]\n",
    "    }\n",
    "]\n",
    "}\n",
    "\n",
    "# Save the intents to a JSON file\n",
    "with open(\"intents.json\", \"w\") as f:\n",
    "    json.dump(J, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da7644",
   "metadata": {},
   "source": [
    "#### Step 2: Data preparation:\n",
    "The second step of this task to create a chatbot with Python and Machine Learning is to prepare the data to train our chatbot. Start this step by importing the necessary libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f569ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []  \n",
    "responses = []\n",
    "\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9689dc26",
   "metadata": {},
   "source": [
    "#### 3.Label Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ae0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels = lbl_encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06795682",
   "metadata": {},
   "source": [
    "#### 4.Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "968cb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8c570",
   "metadata": {},
   "source": [
    "#### 5. Training a Neural Network¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc40d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Win 10\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_1           │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_1           │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.2143 - loss: 2.0768\n",
      "Epoch 2/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2143 - loss: 2.0747\n",
      "Epoch 3/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2143 - loss: 2.0742\n",
      "Epoch 4/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1531 - loss: 2.0739\n",
      "Epoch 5/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1837 - loss: 2.0731\n",
      "Epoch 6/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2143 - loss: 2.0722\n",
      "Epoch 7/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2345 - loss: 2.0715\n",
      "Epoch 8/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2449 - loss: 2.0700\n",
      "Epoch 9/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2143 - loss: 2.0691\n",
      "Epoch 10/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2756 - loss: 2.0683\n",
      "Epoch 11/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2143 - loss: 2.0675\n",
      "Epoch 12/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.2143 - loss: 2.0674\n",
      "Epoch 13/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.2039 - loss: 2.0672\n",
      "Epoch 14/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.2143 - loss: 2.0654\n",
      "Epoch 15/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.2143 - loss: 2.0655\n",
      "Epoch 16/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2143 - loss: 2.0648 \n",
      "Epoch 17/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2143 - loss: 2.0642\n",
      "Epoch 18/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.2143 - loss: 2.0628\n",
      "Epoch 19/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2756 - loss: 2.0628\n",
      "Epoch 20/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.2756 - loss: 2.0630\n",
      "Epoch 21/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3062 - loss: 2.0627\n",
      "Epoch 22/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3570 - loss: 2.0626\n",
      "Epoch 23/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3674 - loss: 2.0615\n",
      "Epoch 24/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3570 - loss: 2.0613\n",
      "Epoch 25/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3674 - loss: 2.0604\n",
      "Epoch 26/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3674 - loss: 2.0586\n",
      "Epoch 27/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.3674 - loss: 2.0587\n",
      "Epoch 28/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.3674 - loss: 2.0586\n",
      "Epoch 29/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3674 - loss: 2.0568\n",
      "Epoch 30/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3570 - loss: 2.0581\n",
      "Epoch 31/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3570 - loss: 2.0576\n",
      "Epoch 32/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3570 - loss: 2.0569\n",
      "Epoch 33/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3674 - loss: 2.0551\n",
      "Epoch 34/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3264 - loss: 2.0554 \n",
      "Epoch 35/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.2652 - loss: 2.0546\n",
      "Epoch 36/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.2756 - loss: 2.0514\n",
      "Epoch 37/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2039 - loss: 2.0532\n",
      "Epoch 38/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2143 - loss: 2.0521\n",
      "Epoch 39/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2143 - loss: 2.0497 \n",
      "Epoch 40/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.2143 - loss: 2.0494\n",
      "Epoch 41/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2039 - loss: 2.0516\n",
      "Epoch 42/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2143 - loss: 2.0502 \n",
      "Epoch 43/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2143 - loss: 2.0498\n",
      "Epoch 44/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2039 - loss: 2.0501\n",
      "Epoch 45/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2143 - loss: 2.0475\n",
      "Epoch 46/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2039 - loss: 2.0476\n",
      "Epoch 47/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2143 - loss: 2.0452\n",
      "Epoch 48/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2039 - loss: 2.0453\n",
      "Epoch 49/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2143 - loss: 2.0411\n",
      "Epoch 50/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2143 - loss: 2.0399\n",
      "Epoch 51/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2143 - loss: 2.0391\n",
      "Epoch 52/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2143 - loss: 2.0412\n",
      "Epoch 53/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2143 - loss: 2.0392\n",
      "Epoch 54/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2143 - loss: 2.0388\n",
      "Epoch 55/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2143 - loss: 2.0397\n",
      "Epoch 56/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2143 - loss: 2.0393\n",
      "Epoch 57/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2039 - loss: 2.0405\n",
      "Epoch 58/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.2039 - loss: 2.0398\n",
      "Epoch 59/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2143 - loss: 2.0374 \n",
      "Epoch 60/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.2143 - loss: 2.0365\n",
      "Epoch 61/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2143 - loss: 2.0356 \n",
      "Epoch 62/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2143 - loss: 2.0334\n",
      "Epoch 63/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2143 - loss: 2.0336\n",
      "Epoch 64/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2143 - loss: 2.0340\n",
      "Epoch 65/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2143 - loss: 2.0356\n",
      "Epoch 66/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.2143 - loss: 2.0331\n",
      "Epoch 67/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.2143 - loss: 2.0315\n",
      "Epoch 68/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.2039 - loss: 2.0330 \n",
      "Epoch 69/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2143 - loss: 2.0256\n",
      "Epoch 70/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2143 - loss: 2.0265\n",
      "Epoch 71/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2143 - loss: 2.0242\n",
      "Epoch 72/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2143 - loss: 2.0272\n",
      "Epoch 73/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2039 - loss: 2.0285\n",
      "Epoch 74/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2039 - loss: 2.0278\n",
      "Epoch 75/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2143 - loss: 2.0217\n",
      "Epoch 76/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2143 - loss: 2.0243\n",
      "Epoch 77/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2143 - loss: 2.0239\n",
      "Epoch 78/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.2143 - loss: 2.0209 \n",
      "Epoch 79/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.2143 - loss: 2.0247 \n",
      "Epoch 80/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2039 - loss: 2.0270\n",
      "Epoch 81/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2143 - loss: 2.0245\n",
      "Epoch 82/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.2143 - loss: 2.0245\n",
      "Epoch 83/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2143 - loss: 2.0224\n",
      "Epoch 84/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2143 - loss: 2.0203\n",
      "Epoch 85/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2143 - loss: 2.0163\n",
      "Epoch 86/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2143 - loss: 2.0158\n",
      "Epoch 87/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2345 - loss: 2.0169\n",
      "Epoch 88/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2756 - loss: 2.0116\n",
      "Epoch 89/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3368 - loss: 2.0123\n",
      "Epoch 90/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3368 - loss: 2.0133\n",
      "Epoch 91/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.3570 - loss: 2.0145\n",
      "Epoch 92/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3674 - loss: 2.0139\n",
      "Epoch 93/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3674 - loss: 2.0119\n",
      "Epoch 94/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3674 - loss: 2.0157\n",
      "Epoch 95/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2756 - loss: 2.0160\n",
      "Epoch 96/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2345 - loss: 2.0175\n",
      "Epoch 97/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.1837 - loss: 2.0166\n",
      "Epoch 98/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1531 - loss: 2.0150\n",
      "Epoch 99/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1837 - loss: 2.0082\n",
      "Epoch 100/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2449 - loss: 2.0056\n",
      "Epoch 101/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2756 - loss: 2.0021\n",
      "Epoch 102/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3570 - loss: 2.0031\n",
      "Epoch 103/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.3674 - loss: 1.9987\n",
      "Epoch 104/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3674 - loss: 1.9928\n",
      "Epoch 105/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3674 - loss: 1.9937\n",
      "Epoch 106/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3674 - loss: 1.9950\n",
      "Epoch 107/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3368 - loss: 1.9902 \n",
      "Epoch 108/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3264 - loss: 1.9955 \n",
      "Epoch 109/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3368 - loss: 1.9908\n",
      "Epoch 110/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3264 - loss: 1.9932\n",
      "Epoch 111/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3264 - loss: 1.9932\n",
      "Epoch 112/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3368 - loss: 1.9867\n",
      "Epoch 113/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3368 - loss: 1.9865\n",
      "Epoch 114/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3368 - loss: 1.9855\n",
      "Epoch 115/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3368 - loss: 1.9857\n",
      "Epoch 116/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3264 - loss: 1.9877\n",
      "Epoch 117/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3368 - loss: 1.9845\n",
      "Epoch 118/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3368 - loss: 1.9838\n",
      "Epoch 119/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3264 - loss: 1.9853\n",
      "Epoch 120/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3368 - loss: 1.9768\n",
      "Epoch 121/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3264 - loss: 1.9820\n",
      "Epoch 122/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3264 - loss: 1.9796\n",
      "Epoch 123/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3368 - loss: 1.9764\n",
      "Epoch 124/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3264 - loss: 1.9765\n",
      "Epoch 125/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3368 - loss: 1.9702\n",
      "Epoch 126/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3368 - loss: 1.9676\n",
      "Epoch 127/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3368 - loss: 1.9691\n",
      "Epoch 128/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3368 - loss: 1.9647\n",
      "Epoch 129/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3264 - loss: 1.9703\n",
      "Epoch 130/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3368 - loss: 1.9653\n",
      "Epoch 131/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3368 - loss: 1.9632\n",
      "Epoch 132/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3368 - loss: 1.9582\n",
      "Epoch 133/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.3368 - loss: 1.9594\n",
      "Epoch 134/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3368 - loss: 1.9588\n",
      "Epoch 135/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3368 - loss: 1.9600\n",
      "Epoch 136/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3264 - loss: 1.9633\n",
      "Epoch 137/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3368 - loss: 1.9605\n",
      "Epoch 138/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3368 - loss: 1.9587\n",
      "Epoch 139/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3570 - loss: 1.9602\n",
      "Epoch 140/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3570 - loss: 1.9576\n",
      "Epoch 141/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3674 - loss: 1.9533\n",
      "Epoch 142/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.3674 - loss: 1.9521\n",
      "Epoch 143/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3674 - loss: 1.9494\n",
      "Epoch 144/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3674 - loss: 1.9478\n",
      "Epoch 145/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3570 - loss: 1.9526\n",
      "Epoch 146/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3674 - loss: 1.9465\n",
      "Epoch 147/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3570 - loss: 1.9481\n",
      "Epoch 148/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.9466\n",
      "Epoch 149/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3674 - loss: 1.9443\n",
      "Epoch 150/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3674 - loss: 1.9431\n",
      "Epoch 151/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3674 - loss: 1.9448\n",
      "Epoch 152/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3674 - loss: 1.9415\n",
      "Epoch 153/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.9426\n",
      "Epoch 154/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3674 - loss: 1.9406\n",
      "Epoch 155/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3674 - loss: 1.9404\n",
      "Epoch 156/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3570 - loss: 1.9377\n",
      "Epoch 157/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3674 - loss: 1.9335\n",
      "Epoch 158/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.9276\n",
      "Epoch 159/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3674 - loss: 1.9285\n",
      "Epoch 160/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3674 - loss: 1.9253\n",
      "Epoch 161/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3570 - loss: 1.9286\n",
      "Epoch 162/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3674 - loss: 1.9249\n",
      "Epoch 163/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3980 - loss: 1.9208\n",
      "Epoch 164/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4489 - loss: 1.9256\n",
      "Epoch 165/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4593 - loss: 1.9175\n",
      "Epoch 166/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4593 - loss: 1.9186\n",
      "Epoch 167/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4489 - loss: 1.9227\n",
      "Epoch 168/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4287 - loss: 1.9192\n",
      "Epoch 169/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4182 - loss: 1.9223\n",
      "Epoch 170/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4593 - loss: 1.9170\n",
      "Epoch 171/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4182 - loss: 1.9248\n",
      "Epoch 172/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4489 - loss: 1.9227\n",
      "Epoch 173/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5101 - loss: 1.9178\n",
      "Epoch 174/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5101 - loss: 1.9101\n",
      "Epoch 175/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4593 - loss: 1.9027\n",
      "Epoch 176/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3674 - loss: 1.8980\n",
      "Epoch 177/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3264 - loss: 1.8981\n",
      "Epoch 178/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3264 - loss: 1.8956\n",
      "Epoch 179/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3368 - loss: 1.8863\n",
      "Epoch 180/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3368 - loss: 1.8831\n",
      "Epoch 181/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3368 - loss: 1.8804\n",
      "Epoch 182/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3264 - loss: 1.8837\n",
      "Epoch 183/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3264 - loss: 1.8810\n",
      "Epoch 184/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3264 - loss: 1.8782\n",
      "Epoch 185/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3674 - loss: 1.8683\n",
      "Epoch 186/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3674 - loss: 1.8669\n",
      "Epoch 187/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.8590\n",
      "Epoch 188/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.8554\n",
      "Epoch 189/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3570 - loss: 1.8633 \n",
      "Epoch 190/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.8508\n",
      "Epoch 191/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3570 - loss: 1.8595\n",
      "Epoch 192/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3570 - loss: 1.8539\n",
      "Epoch 193/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3570 - loss: 1.8543\n",
      "Epoch 194/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3674 - loss: 1.8448\n",
      "Epoch 195/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3570 - loss: 1.8465\n",
      "Epoch 196/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3570 - loss: 1.8457\n",
      "Epoch 197/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.3674 - loss: 1.8383\n",
      "Epoch 198/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3264 - loss: 1.8538\n",
      "Epoch 199/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3368 - loss: 1.8475\n",
      "Epoch 200/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3264 - loss: 1.8581\n",
      "Epoch 201/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3368 - loss: 1.8448\n",
      "Epoch 202/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3368 - loss: 1.8284\n",
      "Epoch 203/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3674 - loss: 1.8180\n",
      "Epoch 204/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.8104\n",
      "Epoch 205/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.8090\n",
      "Epoch 206/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3674 - loss: 1.8077\n",
      "Epoch 207/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3876 - loss: 1.8186\n",
      "Epoch 208/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3980 - loss: 1.8099\n",
      "Epoch 209/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3674 - loss: 1.8145\n",
      "Epoch 210/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3674 - loss: 1.8128\n",
      "Epoch 211/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.8190\n",
      "Epoch 212/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3674 - loss: 1.8054\n",
      "Epoch 213/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4287 - loss: 1.8027\n",
      "Epoch 214/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4899 - loss: 1.7942\n",
      "Epoch 215/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4287 - loss: 1.7882\n",
      "Epoch 216/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4287 - loss: 1.7778\n",
      "Epoch 217/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4182 - loss: 1.7850\n",
      "Epoch 218/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4287 - loss: 1.7717 \n",
      "Epoch 219/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4287 - loss: 1.7689 \n",
      "Epoch 220/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4182 - loss: 1.7708\n",
      "Epoch 221/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4489 - loss: 1.7728\n",
      "Epoch 222/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4489 - loss: 1.7680\n",
      "Epoch 223/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5101 - loss: 1.7703\n",
      "Epoch 224/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4593 - loss: 1.7731\n",
      "Epoch 225/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3876 - loss: 1.7819\n",
      "Epoch 226/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3980 - loss: 1.7738\n",
      "Epoch 227/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4182 - loss: 1.7648\n",
      "Epoch 228/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4489 - loss: 1.7510\n",
      "Epoch 229/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4489 - loss: 1.7463\n",
      "Epoch 230/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4593 - loss: 1.7280\n",
      "Epoch 231/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.4182 - loss: 1.7375\n",
      "Epoch 232/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4287 - loss: 1.7236\n",
      "Epoch 233/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4182 - loss: 1.7251\n",
      "Epoch 234/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3980 - loss: 1.7192\n",
      "Epoch 235/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3980 - loss: 1.7162\n",
      "Epoch 236/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4287 - loss: 1.7046\n",
      "Epoch 237/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4593 - loss: 1.7040\n",
      "Epoch 238/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4489 - loss: 1.7066\n",
      "Epoch 239/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4489 - loss: 1.7090\n",
      "Epoch 240/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4593 - loss: 1.6900\n",
      "Epoch 241/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4593 - loss: 1.6909\n",
      "Epoch 242/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4489 - loss: 1.6896\n",
      "Epoch 243/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4489 - loss: 1.6943\n",
      "Epoch 244/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4593 - loss: 1.6741\n",
      "Epoch 245/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4899 - loss: 1.6713\n",
      "Epoch 246/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5101 - loss: 1.6752 \n",
      "Epoch 247/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.6706\n",
      "Epoch 248/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5205 - loss: 1.6694\n",
      "Epoch 249/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.6675\n",
      "Epoch 250/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5205 - loss: 1.6582\n",
      "Epoch 251/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5101 - loss: 1.6690\n",
      "Epoch 252/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.6512\n",
      "Epoch 253/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4795 - loss: 1.6638\n",
      "Epoch 254/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4795 - loss: 1.6602\n",
      "Epoch 255/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5101 - loss: 1.6455\n",
      "Epoch 256/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5101 - loss: 1.6454 \n",
      "Epoch 257/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5101 - loss: 1.6403\n",
      "Epoch 258/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5205 - loss: 1.6295\n",
      "Epoch 259/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5101 - loss: 1.6386\n",
      "Epoch 260/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5205 - loss: 1.6235\n",
      "Epoch 261/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.6207\n",
      "Epoch 262/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5205 - loss: 1.6111\n",
      "Epoch 263/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.6270\n",
      "Epoch 264/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4795 - loss: 1.6163\n",
      "Epoch 265/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5101 - loss: 1.6205\n",
      "Epoch 266/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5205 - loss: 1.6021\n",
      "Epoch 267/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5205 - loss: 1.5989\n",
      "Epoch 268/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.6107\n",
      "Epoch 269/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5101 - loss: 1.6139\n",
      "Epoch 270/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4899 - loss: 1.6081\n",
      "Epoch 271/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4899 - loss: 1.6035\n",
      "Epoch 272/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4899 - loss: 1.6026\n",
      "Epoch 273/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4795 - loss: 1.6014 \n",
      "Epoch 274/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5101 - loss: 1.5939\n",
      "Epoch 275/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5205 - loss: 1.5642\n",
      "Epoch 276/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.5646\n",
      "Epoch 277/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4795 - loss: 1.5725\n",
      "Epoch 278/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4593 - loss: 1.5661\n",
      "Epoch 279/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4182 - loss: 1.5890\n",
      "Epoch 280/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4287 - loss: 1.5725\n",
      "Epoch 281/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4182 - loss: 1.5757\n",
      "Epoch 282/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4489 - loss: 1.5591\n",
      "Epoch 283/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5101 - loss: 1.5448\n",
      "Epoch 284/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.5386\n",
      "Epoch 285/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4795 - loss: 1.5417\n",
      "Epoch 286/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4899 - loss: 1.5395\n",
      "Epoch 287/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4899 - loss: 1.5393\n",
      "Epoch 288/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5101 - loss: 1.5486 \n",
      "Epoch 289/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5205 - loss: 1.5416\n",
      "Epoch 290/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5101 - loss: 1.5391\n",
      "Epoch 291/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5205 - loss: 1.5144\n",
      "Epoch 292/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5205 - loss: 1.5145\n",
      "Epoch 293/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4899 - loss: 1.5216\n",
      "Epoch 294/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4489 - loss: 1.5354\n",
      "Epoch 295/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4593 - loss: 1.5205\n",
      "Epoch 296/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4489 - loss: 1.5270\n",
      "Epoch 297/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4899 - loss: 1.5038\n",
      "Epoch 298/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5101 - loss: 1.5106\n",
      "Epoch 299/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5205 - loss: 1.4940\n",
      "Epoch 300/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5101 - loss: 1.5055\n",
      "Epoch 301/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5205 - loss: 1.4943\n",
      "Epoch 302/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.4977\n",
      "Epoch 303/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.4850\n",
      "Epoch 304/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5101 - loss: 1.4942\n",
      "Epoch 305/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5101 - loss: 1.4976\n",
      "Epoch 306/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5205 - loss: 1.4752\n",
      "Epoch 307/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5205 - loss: 1.4782\n",
      "Epoch 308/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.4834\n",
      "Epoch 309/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5407 - loss: 1.4734\n",
      "Epoch 310/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5407 - loss: 1.4748\n",
      "Epoch 311/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5205 - loss: 1.4573\n",
      "Epoch 312/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.4446\n",
      "Epoch 313/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5101 - loss: 1.4552\n",
      "Epoch 314/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5205 - loss: 1.4356\n",
      "Epoch 315/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.4408\n",
      "Epoch 316/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5101 - loss: 1.4523\n",
      "Epoch 317/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5205 - loss: 1.4362\n",
      "Epoch 318/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5205 - loss: 1.4349\n",
      "Epoch 319/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5205 - loss: 1.4321\n",
      "Epoch 320/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5205 - loss: 1.4216\n",
      "Epoch 321/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4899 - loss: 1.4214\n",
      "Epoch 322/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.4311\n",
      "Epoch 323/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5511 - loss: 1.4223\n",
      "Epoch 324/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5407 - loss: 1.4238\n",
      "Epoch 325/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5511 - loss: 1.4113\n",
      "Epoch 326/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5713 - loss: 1.4213\n",
      "Epoch 327/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5818 - loss: 1.4055\n",
      "Epoch 328/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5713 - loss: 1.4128\n",
      "Epoch 329/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5818 - loss: 1.4029\n",
      "Epoch 330/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5713 - loss: 1.4081\n",
      "Epoch 331/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5818 - loss: 1.3924\n",
      "Epoch 332/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5713 - loss: 1.3961\n",
      "Epoch 333/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5713 - loss: 1.3898\n",
      "Epoch 334/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5407 - loss: 1.3981\n",
      "Epoch 335/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5407 - loss: 1.3905 \n",
      "Epoch 336/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5511 - loss: 1.3838\n",
      "Epoch 337/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5511 - loss: 1.3689\n",
      "Epoch 338/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5407 - loss: 1.3755\n",
      "Epoch 339/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5511 - loss: 1.3693\n",
      "Epoch 340/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5407 - loss: 1.3718\n",
      "Epoch 341/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5511 - loss: 1.3584\n",
      "Epoch 342/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5511 - loss: 1.3588\n",
      "Epoch 343/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.3580\n",
      "Epoch 344/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5407 - loss: 1.3575\n",
      "Epoch 345/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5407 - loss: 1.3539\n",
      "Epoch 346/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5101 - loss: 1.3556\n",
      "Epoch 347/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5101 - loss: 1.3628\n",
      "Epoch 348/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5407 - loss: 1.3463\n",
      "Epoch 349/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.3515\n",
      "Epoch 350/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5205 - loss: 1.3332\n",
      "Epoch 351/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5101 - loss: 1.3530\n",
      "Epoch 352/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.3374\n",
      "Epoch 353/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5101 - loss: 1.3359 \n",
      "Epoch 354/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5101 - loss: 1.3372\n",
      "Epoch 355/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5101 - loss: 1.3339\n",
      "Epoch 356/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5101 - loss: 1.3322\n",
      "Epoch 357/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5205 - loss: 1.3114\n",
      "Epoch 358/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5101 - loss: 1.3193\n",
      "Epoch 359/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5101 - loss: 1.3155\n",
      "Epoch 360/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5101 - loss: 1.3107\n",
      "Epoch 361/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.3118\n",
      "Epoch 362/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5205 - loss: 1.2914\n",
      "Epoch 363/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5101 - loss: 1.3025\n",
      "Epoch 364/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5205 - loss: 1.2790\n",
      "Epoch 365/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5205 - loss: 1.2859\n",
      "Epoch 366/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5101 - loss: 1.3043\n",
      "Epoch 367/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5101 - loss: 1.3040\n",
      "Epoch 368/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5101 - loss: 1.2947\n",
      "Epoch 369/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5407 - loss: 1.2853\n",
      "Epoch 370/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5407 - loss: 1.2728\n",
      "Epoch 371/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5511 - loss: 1.2681\n",
      "Epoch 372/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5511 - loss: 1.2565\n",
      "Epoch 373/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5511 - loss: 1.2615\n",
      "Epoch 374/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5407 - loss: 1.2695\n",
      "Epoch 375/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6020 - loss: 1.2681\n",
      "Epoch 376/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6020 - loss: 1.2679\n",
      "Epoch 377/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6326 - loss: 1.2646\n",
      "Epoch 378/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6326 - loss: 1.2788\n",
      "Epoch 379/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5818 - loss: 1.2691\n",
      "Epoch 380/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5713 - loss: 1.2951\n",
      "Epoch 381/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5713 - loss: 1.2871\n",
      "Epoch 382/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6124 - loss: 1.2480\n",
      "Epoch 383/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6020 - loss: 1.2457\n",
      "Epoch 384/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6020 - loss: 1.2421\n",
      "Epoch 385/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5101 - loss: 1.2614\n",
      "Epoch 386/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5205 - loss: 1.2724\n",
      "Epoch 387/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4899 - loss: 1.2807\n",
      "Epoch 388/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4795 - loss: 1.2711\n",
      "Epoch 389/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5511 - loss: 1.2258\n",
      "Epoch 390/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.2169\n",
      "Epoch 391/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5407 - loss: 1.2308\n",
      "Epoch 392/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.2169\n",
      "Epoch 393/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.2161\n",
      "Epoch 394/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5101 - loss: 1.2272\n",
      "Epoch 395/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.2083\n",
      "Epoch 396/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.2281\n",
      "Epoch 397/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5101 - loss: 1.2239\n",
      "Epoch 398/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5205 - loss: 1.2111\n",
      "Epoch 399/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.2210\n",
      "Epoch 400/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.2323\n",
      "Epoch 401/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.2298\n",
      "Epoch 402/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5205 - loss: 1.2130\n",
      "Epoch 403/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.2211\n",
      "Epoch 404/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5101 - loss: 1.2129\n",
      "Epoch 405/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5205 - loss: 1.1958\n",
      "Epoch 406/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5101 - loss: 1.2166\n",
      "Epoch 407/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5407 - loss: 1.2219\n",
      "Epoch 408/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5511 - loss: 1.2105\n",
      "Epoch 409/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5511 - loss: 1.2053\n",
      "Epoch 410/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5511 - loss: 1.1809\n",
      "Epoch 411/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5205 - loss: 1.1659\n",
      "Epoch 412/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5407 - loss: 1.1659\n",
      "Epoch 413/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5511 - loss: 1.1534\n",
      "Epoch 414/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5407 - loss: 1.1695\n",
      "Epoch 415/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5511 - loss: 1.1476\n",
      "Epoch 416/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5407 - loss: 1.1679\n",
      "Epoch 417/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5407 - loss: 1.1622\n",
      "Epoch 418/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5407 - loss: 1.1557\n",
      "Epoch 419/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5713 - loss: 1.1468\n",
      "Epoch 420/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.1335\n",
      "Epoch 421/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.1253\n",
      "Epoch 422/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5407 - loss: 1.1409\n",
      "Epoch 423/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5511 - loss: 1.1215\n",
      "Epoch 424/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5407 - loss: 1.1401\n",
      "Epoch 425/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5407 - loss: 1.1399\n",
      "Epoch 426/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5511 - loss: 1.1229\n",
      "Epoch 427/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5511 - loss: 1.1192\n",
      "Epoch 428/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5407 - loss: 1.1259\n",
      "Epoch 429/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.1137\n",
      "Epoch 430/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5713 - loss: 1.1212\n",
      "Epoch 431/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5818 - loss: 1.1242\n",
      "Epoch 432/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6124 - loss: 1.1180\n",
      "Epoch 433/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6326 - loss: 1.1172\n",
      "Epoch 434/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6124 - loss: 1.0999\n",
      "Epoch 435/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5407 - loss: 1.1101\n",
      "Epoch 436/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5407 - loss: 1.1139\n",
      "Epoch 437/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5407 - loss: 1.1186\n",
      "Epoch 438/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.1137\n",
      "Epoch 439/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5407 - loss: 1.1200\n",
      "Epoch 440/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5407 - loss: 1.1028\n",
      "Epoch 441/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5407 - loss: 1.0923\n",
      "Epoch 442/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5713 - loss: 1.0857\n",
      "Epoch 443/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6020 - loss: 1.0987\n",
      "Epoch 444/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6020 - loss: 1.0969\n",
      "Epoch 445/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6020 - loss: 1.1040\n",
      "Epoch 446/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6124 - loss: 1.0819\n",
      "Epoch 447/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6326 - loss: 1.0847\n",
      "Epoch 448/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6326 - loss: 1.0663\n",
      "Epoch 449/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5818 - loss: 1.0501\n",
      "Epoch 450/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.0629\n",
      "Epoch 451/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5407 - loss: 1.0892\n",
      "Epoch 452/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5511 - loss: 1.0662 \n",
      "Epoch 453/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5407 - loss: 1.0580\n",
      "Epoch 454/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5713 - loss: 1.0513\n",
      "Epoch 455/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6326 - loss: 1.0439\n",
      "Epoch 456/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6430 - loss: 1.0373\n",
      "Epoch 457/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6326 - loss: 1.0456\n",
      "Epoch 458/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6430 - loss: 1.0330\n",
      "Epoch 459/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6326 - loss: 1.0474\n",
      "Epoch 460/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6326 - loss: 1.0446\n",
      "Epoch 461/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.0366\n",
      "Epoch 462/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5511 - loss: 1.0437\n",
      "Epoch 463/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5713 - loss: 1.0505\n",
      "Epoch 464/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5713 - loss: 1.0320\n",
      "Epoch 465/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5818 - loss: 1.0093\n",
      "Epoch 466/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5818 - loss: 1.0140\n",
      "Epoch 467/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5818 - loss: 1.0093\n",
      "Epoch 468/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5818 - loss: 1.0073\n",
      "Epoch 469/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6430 - loss: 1.0065\n",
      "Epoch 470/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6736 - loss: 1.0034\n",
      "Epoch 471/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6736 - loss: 1.0034\n",
      "Epoch 472/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6632 - loss: 1.0152\n",
      "Epoch 473/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6632 - loss: 1.0048\n",
      "Epoch 474/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6736 - loss: 0.9936\n",
      "Epoch 475/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6326 - loss: 1.0011\n",
      "Epoch 476/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6326 - loss: 0.9978\n",
      "Epoch 477/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6326 - loss: 1.0052\n",
      "Epoch 478/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5818 - loss: 0.9935\n",
      "Epoch 479/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5713 - loss: 0.9955\n",
      "Epoch 480/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5713 - loss: 0.9844\n",
      "Epoch 481/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6124 - loss: 0.9728\n",
      "Epoch 482/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6326 - loss: 0.9856\n",
      "Epoch 483/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6632 - loss: 0.9760\n",
      "Epoch 484/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6326 - loss: 0.9731\n",
      "Epoch 485/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6124 - loss: 0.9657\n",
      "Epoch 486/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6124 - loss: 0.9659\n",
      "Epoch 487/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6124 - loss: 0.9731\n",
      "Epoch 488/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6124 - loss: 0.9656\n",
      "Epoch 489/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6020 - loss: 0.9666\n",
      "Epoch 490/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6326 - loss: 0.9603\n",
      "Epoch 491/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6736 - loss: 0.9624\n",
      "Epoch 492/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6938 - loss: 0.9891\n",
      "Epoch 493/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6938 - loss: 0.9997\n",
      "Epoch 494/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6938 - loss: 0.9976\n",
      "Epoch 495/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6938 - loss: 0.9808\n",
      "Epoch 496/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6632 - loss: 0.9673\n",
      "Epoch 497/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6430 - loss: 0.9373\n",
      "Epoch 498/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6326 - loss: 0.9522\n",
      "Epoch 499/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6430 - loss: 0.9400\n",
      "Epoch 500/500\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6020 - loss: 0.9550\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "epochs = 500\n",
    "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fcd78dc-4078-4789-8045-f6baf5b87eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4b7828",
   "metadata": {},
   "source": [
    "#### 6. Saving The Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15107879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# to save the trained model\n",
    "model.save(\"chat_model.h5\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# to save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# to save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824408c5",
   "metadata": {},
   "source": [
    "#### 7.Chatbot Design with Trained Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27815937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quit\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model.h5')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f89a09",
   "metadata": {},
   "source": [
    "# 5. Chatbot using LogisticRegression and Making it as web Application\n",
    "- Steps to Build Chat Web Application\n",
    "- Define Intents\n",
    "- Create training data\n",
    "- Train the chatbot\n",
    "- Build the chatbot\n",
    "- Test the chatbot\n",
    "- Deploy the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf0e04d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Win\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import ssl\n",
    "import streamlit as st\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "nltk.data.path.append(os.path.abspath(\"nltk_data\"))\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05944a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"How are you\", \"What's up\"],\n",
    "        \"responses\": [\"Hi there\", \"Hello\", \"Hey\", \"I'm fine, thank you\", \"Nothing much\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Take care\"],\n",
    "        \"responses\": [\"Goodbye\", \"See you later\", \"Take care\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"Thank you\", \"Thanks\", \"Thanks a lot\", \"I appreciate it\"],\n",
    "        \"responses\": [\"You're welcome\", \"No problem\", \"Glad I could help\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"about\",\n",
    "        \"patterns\": [\"What can you do\", \"Who are you\", \"What are you\", \"What is your purpose\"],\n",
    "        \"responses\": [\"I am a chatbot\", \"My purpose is to assist you\", \"I can answer questions and provide assistance\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"help\",\n",
    "        \"patterns\": [\"Help\", \"I need help\", \"Can you help me\", \"What should I do\"],\n",
    "        \"responses\": [\"Sure, what do you need help with?\", \"I'm here to help. What's the problem?\", \"How can I assist you?\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"age\",\n",
    "        \"patterns\": [\"How old are you\", \"What's your age\"],\n",
    "        \"responses\": [\"I don't have an age. I'm a chatbot.\", \"I was just born in the digital world.\", \"Age is just a number for me.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"weather\",\n",
    "        \"patterns\": [\"What's the weather like\", \"How's the weather today\"],\n",
    "        \"responses\": [\"I'm sorry, I cannot provide real-time weather information.\", \"You can check the weather on a weather app or website.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"budget\",\n",
    "        \"patterns\": [\"How can I make a budget\", \"What's a good budgeting strategy\", \"How do I create a budget\"],\n",
    "        \"responses\": [\"To make a budget, start by tracking your income and expenses. Then, allocate your income towards essential expenses like rent, food, and bills. Next, allocate some of your income towards savings and debt repayment. Finally, allocate the remainder of your income towards discretionary expenses like entertainment and hobbies.\", \"A good budgeting strategy is to use the 50/30/20 rule. This means allocating 50% of your income towards essential expenses, 30% towards discretionary expenses, and 20% towards savings and debt repayment.\", \"To create a budget, start by setting financial goals for yourself. Then, track your income and expenses for a few months to get a sense of where your money is going. Next, create a budget by allocating your income towards essential expenses, savings and debt repayment, and discretionary expenses.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"credit_score\",\n",
    "        \"patterns\": [\"What is a credit score\", \"How do I check my credit score\", \"How can I improve my credit score\"],\n",
    "        \"responses\": [\"A credit score is a number that represents your creditworthiness. It is based on your credit history and is used by lenders to determine whether or not to lend you money. The higher your credit score, the more likely you are to be approved for credit.\", \"You can check your credit score for free on several websites such as Credit Karma and Credit Sesame.\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f5c0bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the vectorizer and classifier\n",
    "vectorizer = TfidfVectorizer()\n",
    "clf = LogisticRegression(random_state=0, max_iter=10000)\n",
    "\n",
    "# Preprocess the data\n",
    "tags = []\n",
    "patterns = []\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        tags.append(intent['tag'])\n",
    "        patterns.append(pattern)\n",
    "\n",
    "# training the model\n",
    "x = vectorizer.fit_transform(patterns)\n",
    "y = tags\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f22ff7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(input_text):\n",
    "    input_text = vectorizer.transform([input_text])\n",
    "    tag = clf.predict(input_text)[0]\n",
    "    for intent in intents:\n",
    "        if intent['tag'] == tag:\n",
    "            response = random.choice(intent['responses'])\n",
    "            return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "594205d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 16:56:14.441 \n",
      "  Warning: to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Win 10\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-05-23 16:56:14.445 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "def main():\n",
    "    global counter\n",
    "    st.title(\"shaheel-Chatbot\")\n",
    "    st.write(\"Welcome to the chatbot. Please type a message and press Enter to start the conversation.\")\n",
    "\n",
    "    counter += 1\n",
    "    user_input = st.text_input(\"You:\", key=f\"user_input_{counter}\")\n",
    "\n",
    "    if user_input:\n",
    "        response = chatbot(user_input)\n",
    "        st.text_area(\"shaheel-Chatbot:\", value=response, height=100, max_chars=None, key=f\"chatbot_response_{counter}\")\n",
    "\n",
    "        if response.lower() in ['goodbye', 'bye']:\n",
    "            st.write(\"Thank you for chatting with me. Have a great day!\")\n",
    "            st.stop()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f0dc8",
   "metadata": {},
   "source": [
    "# Chatbot-6 API based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af6c2af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\win 10\\anaconda3\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\win 10\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.11)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\win 10\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\win 10\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wolframalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd50426",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa5898d5-04d1-411c-8d1f-b1409605f062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efeae1-b298-4b33-bd08-d3b0e3ef6342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17249d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python package supporting common text-to-speech engines\n",
    "import pyttsx3\n",
    "  \n",
    "# For understanding speech\n",
    "import speech_recognition as sr\n",
    "  \n",
    "# For fetching the answers to computational queries\n",
    "import wolframalpha\n",
    "  \n",
    "# for fetching wikipedia articles\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3cc42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search the query that is either entered or spoken by user\n",
    "def search(query):\n",
    "      \n",
    "    # try is used for searching with wolframAlpha\n",
    "    try:\n",
    "          \n",
    "        # Generate your App ID from WolframAlpha \n",
    "        app_id = \"Your WolframAlpha App ID here\"\n",
    "        client = wolframalpha.Client(ULVYEJ-KXH8TGLUR9)\n",
    "        res = client.query(query)\n",
    "        answer = next(res.results).text\n",
    "        print(answer)\n",
    "        SpeakText(\"Your answer is \" + answer)\n",
    "          \n",
    "    # If the query cannot be searched using WolframAlpha then it is searched in wikipedia\n",
    "    except:\n",
    "          \n",
    "        query = query.split(' ') \n",
    "        query = \" \".join(query[0:])\n",
    "          \n",
    "        SpeakText(\"shaheel Robo is searching for \" + query)\n",
    "        print(wikipedia.summary(query, sentences = 3))\n",
    "        SpeakText(wikipedia.summary(query, \n",
    "                                      sentences = 3))\n",
    "        # Function to convert text to \n",
    "# speech \n",
    "def SpeakText(command): \n",
    "        \n",
    "    # Initialize the engine \n",
    "    engine = pyttsx3.init() \n",
    "    engine.say(command)  \n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c2f8260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\n",
      "Python is dynamically type-checked and garbage-collected.\n"
     ]
    }
   ],
   "source": [
    "# Driver's code\n",
    "# input query from the user by \n",
    "# typing or by voice\n",
    "query = input()\n",
    "query = query.lower()\n",
    "  \n",
    "# if query is blank then user \n",
    "# is prompted to speak something.\n",
    "if query == '': \n",
    "    r = sr.Recognizer()\n",
    "  \n",
    "    # uses the default microphone\n",
    "    # as the source to record voice\n",
    "    with sr.Microphone() as source:  \n",
    "        print(\"Say Something \")\n",
    "  \n",
    "        # reduces the background disturbances\n",
    "        # and noise for 2 seconds\n",
    "        r.adjust_for_ambient_noise(source, 2)  \n",
    "          \n",
    "        # listening to source\n",
    "        audio = r.listen(source)  \n",
    "    try:\n",
    "        speech = r.recognize_google(audio)\n",
    "        search(speech)\n",
    "  \n",
    "    # Handling Exceptions if speech \n",
    "    # is not understood.\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not \\\n",
    "        understand audio\")\n",
    "  \n",
    "    # Couldn't handle requests, occurs \n",
    "    # mainly because of network errors\n",
    "    except sr.RequestError as e:  \n",
    "        print(\"Could not request results from Google \\\n",
    "        Speech Recognition service;{0}\".format(e))\n",
    "else:\n",
    "    search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09474c",
   "metadata": {},
   "source": [
    "# 7.Chatbot Design with Keras & Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fb6eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8220c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []  \n",
    "responses = []\n",
    "\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef87db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels = lbl_encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73df0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3aac2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_2           │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_2           │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 2s 2s/step - accuracy: 0.0938 - loss: 2.079 ━━━━━━━━━━━━━━━━━━━━ 2s 67ms/step - accuracy: 0.1121 - loss: 2.0793\n",
      "Epoch 2/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2188 - loss: 2.077 ━━━━━━━━━━━━━━━━━━━━ 0s 153ms/step - accuracy: 0.2143 - loss: 2.0780\n",
      "Epoch 3/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2188 - loss: 2.076 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2143 - loss: 2.0770\n",
      "Epoch 4/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.2188 - loss: 2.076 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2143 - loss: 2.0764\n",
      "Epoch 5/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.2188 - loss: 2.075 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2143 - loss: 2.0758\n",
      "Epoch 6/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1875 - loss: 2.076 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2039 - loss: 2.0755\n",
      "Epoch 7/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2188 - loss: 2.074 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.2143 - loss: 2.0746\n",
      "Epoch 8/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2188 - loss: 2.073 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2143 - loss: 2.0739\n",
      "Epoch 9/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 2.073 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2143 - loss: 2.0735\n",
      "Epoch 10/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2188 - loss: 2.072 ━━━━━━━━━━━━━━━━━━━━ 0s 121ms/step - accuracy: 0.2143 - loss: 2.0731\n",
      "Epoch 11/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 124ms/step - accuracy: 0.2188 - loss: 2.07 ━━━━━━━━━━━━━━━━━━━━ 0s 131ms/step - accuracy: 0.2143 - loss: 2.0727\n",
      "Epoch 12/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 123ms/step - accuracy: 0.2188 - loss: 2.07 ━━━━━━━━━━━━━━━━━━━━ 0s 132ms/step - accuracy: 0.2143 - loss: 2.0716\n",
      "Epoch 13/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 156ms/step - accuracy: 0.1875 - loss: 2.07 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2039 - loss: 2.0719 \n",
      "Epoch 14/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1875 - loss: 2.072 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2039 - loss: 2.0715\n",
      "Epoch 15/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 249ms/step - accuracy: 0.2188 - loss: 2.07 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2143 - loss: 2.0706 \n",
      "Epoch 16/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 2.070 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.2143 - loss: 2.0698\n",
      "Epoch 17/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 2.069 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.2143 - loss: 2.0691\n",
      "Epoch 18/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 2.069 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2143 - loss: 2.0689\n",
      "Epoch 19/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.1875 - loss: 2.069 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2039 - loss: 2.0686\n",
      "Epoch 20/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.1875 - loss: 2.068 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2039 - loss: 2.0679\n",
      "Epoch 21/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.2188 - loss: 2.067 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.2143 - loss: 2.0670\n",
      "Epoch 22/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.2500 - loss: 2.063 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.2449 - loss: 2.0652\n",
      "Epoch 23/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.3438 - loss: 2.065 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3368 - loss: 2.0653\n",
      "Epoch 24/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2812 - loss: 2.066 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2958 - loss: 2.0653\n",
      "Epoch 25/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2188 - loss: 2.063 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 2.0638\n",
      "Epoch 26/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2188 - loss: 2.062 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2143 - loss: 2.0629\n",
      "Epoch 27/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2188 - loss: 2.062 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2143 - loss: 2.0625\n",
      "Epoch 28/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2188 - loss: 2.060 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2143 - loss: 2.0612\n",
      "Epoch 29/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.2188 - loss: 2.06 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2143 - loss: 2.0603 \n",
      "Epoch 30/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 2.061 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2143 - loss: 2.0602\n",
      "Epoch 31/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 2.059 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2143 - loss: 2.0590\n",
      "Epoch 32/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3438 - loss: 2.058 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3368 - loss: 2.0580\n",
      "Epoch 33/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3125 - loss: 2.059 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3264 - loss: 2.0580\n",
      "Epoch 34/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2500 - loss: 2.058 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2652 - loss: 2.0571\n",
      "Epoch 35/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2500 - loss: 2.058 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2652 - loss: 2.0563\n",
      "Epoch 36/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2812 - loss: 2.054 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2756 - loss: 2.0545\n",
      "Epoch 37/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2812 - loss: 2.049 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2756 - loss: 2.0522\n",
      "Epoch 38/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2500 - loss: 2.053 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2449 - loss: 2.0528\n",
      "Epoch 39/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2500 - loss: 2.052 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.2449 - loss: 2.0519\n",
      "Epoch 40/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2500 - loss: 2.050 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2449 - loss: 2.0508\n",
      "Epoch 41/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2500 - loss: 2.050 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2449 - loss: 2.0502\n",
      "Epoch 42/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.2500 - loss: 2.051 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2449 - loss: 2.0501\n",
      "Epoch 43/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2500 - loss: 2.044 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2449 - loss: 2.0472\n",
      "Epoch 44/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.2812 - loss: 2.047 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2756 - loss: 2.0474\n",
      "Epoch 45/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3438 - loss: 2.041 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3368 - loss: 2.0448\n",
      "Epoch 46/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.1875 - loss: 2.048 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2039 - loss: 2.0465\n",
      "Epoch 47/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2188 - loss: 2.046 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.2143 - loss: 2.0455\n",
      "Epoch 48/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2188 - loss: 2.040 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2143 - loss: 2.0426\n",
      "Epoch 49/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2188 - loss: 2.036 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2143 - loss: 2.0407\n",
      "Epoch 50/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2188 - loss: 2.036 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2143 - loss: 2.0400\n",
      "Epoch 51/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 2.035 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2143 - loss: 2.0392\n",
      "Epoch 52/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.1875 - loss: 2.044 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2039 - loss: 2.0420\n",
      "Epoch 53/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.2188 - loss: 2.036 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2143 - loss: 2.0393\n",
      "Epoch 54/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.2188 - loss: 2.040 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2143 - loss: 2.0409\n",
      "Epoch 55/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.1875 - loss: 2.045 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2039 - loss: 2.0429\n",
      "Epoch 56/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.1875 - loss: 2.045 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2039 - loss: 2.0425\n",
      "Epoch 57/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 2.039 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2143 - loss: 2.0401\n",
      "Epoch 58/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2188 - loss: 2.041 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2143 - loss: 2.0402\n",
      "Epoch 59/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 2.038 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.2143 - loss: 2.0387\n",
      "Epoch 60/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2188 - loss: 2.039 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2143 - loss: 2.0385\n",
      "Epoch 61/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 123ms/step - accuracy: 0.2188 - loss: 2.03 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 2.0370 \n",
      "Epoch 62/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.1875 - loss: 2.041 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2039 - loss: 2.0377\n",
      "Epoch 63/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.1875 - loss: 2.040 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.2039 - loss: 2.0365\n",
      "Epoch 64/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 126ms/step - accuracy: 0.2188 - loss: 2.03 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2143 - loss: 2.0331 \n",
      "Epoch 65/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.1875 - loss: 2.038 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2039 - loss: 2.0340\n",
      "Epoch 66/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2188 - loss: 2.027 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2143 - loss: 2.0299\n",
      "Epoch 67/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 2.028 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2143 - loss: 2.0295\n",
      "Epoch 68/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2188 - loss: 2.027 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2143 - loss: 2.0282\n",
      "Epoch 69/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 2.019 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.2143 - loss: 2.0255\n",
      "Epoch 70/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.1875 - loss: 2.035 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2039 - loss: 2.0303\n",
      "Epoch 71/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2188 - loss: 2.027 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2143 - loss: 2.0275\n",
      "Epoch 72/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2188 - loss: 2.026 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2143 - loss: 2.0269\n",
      "Epoch 73/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.2188 - loss: 2.028 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 2.0271\n",
      "Epoch 74/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 2.022 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.2143 - loss: 2.0247\n",
      "Epoch 75/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 2.024 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 2.0241\n",
      "Epoch 76/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.1875 - loss: 2.030 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2039 - loss: 2.0251\n",
      "Epoch 77/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2188 - loss: 2.023 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2143 - loss: 2.0219\n",
      "Epoch 78/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2188 - loss: 2.011 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2143 - loss: 2.0168\n",
      "Epoch 79/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2188 - loss: 2.021 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2143 - loss: 2.0190\n",
      "Epoch 80/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.1875 - loss: 2.024 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2039 - loss: 2.0192\n",
      "Epoch 81/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2188 - loss: 2.015 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2143 - loss: 2.0153\n",
      "Epoch 82/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2188 - loss: 2.012 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 2.0133\n",
      "Epoch 83/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.1875 - loss: 2.020 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2039 - loss: 2.0151\n",
      "Epoch 84/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 2.010 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2143 - loss: 2.0108\n",
      "Epoch 85/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 2.016 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2143 - loss: 2.0120\n",
      "Epoch 86/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2188 - loss: 2.009 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 2.0091\n",
      "Epoch 87/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2188 - loss: 2.002 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2143 - loss: 2.0070\n",
      "Epoch 88/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2188 - loss: 2.009 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2143 - loss: 2.0092\n",
      "Epoch 89/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2188 - loss: 2.015 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2143 - loss: 2.0108\n",
      "Epoch 90/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2188 - loss: 2.008 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2143 - loss: 2.0080\n",
      "Epoch 91/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2812 - loss: 2.007 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.2756 - loss: 2.0073\n",
      "Epoch 92/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 2.007 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3674 - loss: 2.0065\n",
      "Epoch 93/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 122ms/step - accuracy: 0.3438 - loss: 2.01 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 2.0080 \n",
      "Epoch 94/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3125 - loss: 2.011 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3264 - loss: 2.0068\n",
      "Epoch 95/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3125 - loss: 2.004 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3062 - loss: 2.0039\n",
      "Epoch 96/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2812 - loss: 2.010 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2958 - loss: 2.0049\n",
      "Epoch 97/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2812 - loss: 2.009 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2958 - loss: 2.0042\n",
      "Epoch 98/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.3438 - loss: 2.009 ━━━━━━━━━━━━━━━━━━━━ 0s 150ms/step - accuracy: 0.3570 - loss: 2.0033\n",
      "Epoch 99/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3750 - loss: 1.990 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3674 - loss: 1.9963\n",
      "Epoch 100/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3438 - loss: 2.008 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3570 - loss: 2.0016\n",
      "Epoch 101/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3750 - loss: 1.988 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3674 - loss: 1.9945\n",
      "Epoch 102/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.999 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3674 - loss: 1.9977\n",
      "Epoch 103/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3750 - loss: 1.999 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.3674 - loss: 1.9970\n",
      "Epoch 104/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3750 - loss: 1.996 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3674 - loss: 1.9959\n",
      "Epoch 105/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3438 - loss: 2.005 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3570 - loss: 1.9986\n",
      "Epoch 106/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3438 - loss: 2.005 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3570 - loss: 1.9983\n",
      "Epoch 107/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3438 - loss: 2.004 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3570 - loss: 1.9976\n",
      "Epoch 108/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2188 - loss: 1.973 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2143 - loss: 1.9867\n",
      "Epoch 109/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2188 - loss: 2.002 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2143 - loss: 1.9955\n",
      "Epoch 110/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 1.971 ━━━━━━━━━━━━━━━━━━━━ 0s 116ms/step - accuracy: 0.2143 - loss: 1.9842\n",
      "Epoch 111/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2188 - loss: 1.977 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2143 - loss: 1.9854\n",
      "Epoch 112/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1875 - loss: 2.001 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2039 - loss: 1.9927\n",
      "Epoch 113/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 1.982 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2143 - loss: 1.9868\n",
      "Epoch 114/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2188 - loss: 1.992 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2143 - loss: 1.9913\n",
      "Epoch 115/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 1.979 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2143 - loss: 1.9878\n",
      "Epoch 116/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 1.995 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2143 - loss: 1.9939\n",
      "Epoch 117/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 1.977 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2143 - loss: 1.9889\n",
      "Epoch 118/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.2188 - loss: 2.001 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2143 - loss: 1.9970\n",
      "Epoch 119/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.2188 - loss: 1.976 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2143 - loss: 1.9884\n",
      "Epoch 120/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.2188 - loss: 1.984 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2143 - loss: 1.9904\n",
      "Epoch 121/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2188 - loss: 1.985 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2143 - loss: 1.9894\n",
      "Epoch 122/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2188 - loss: 1.995 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2143 - loss: 1.9907\n",
      "Epoch 123/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2188 - loss: 1.980 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2143 - loss: 1.9840\n",
      "Epoch 124/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.2188 - loss: 1.986 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 1.9843\n",
      "Epoch 125/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.2188 - loss: 1.978 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2143 - loss: 1.9806\n",
      "Epoch 126/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 1.977 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 1.9790\n",
      "Epoch 127/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2188 - loss: 1.987 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2143 - loss: 1.9822\n",
      "Epoch 128/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 1.982 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 1.9802\n",
      "Epoch 129/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3438 - loss: 1.968 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3368 - loss: 1.9757\n",
      "Epoch 130/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3750 - loss: 1.962 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3674 - loss: 1.9739\n",
      "Epoch 131/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3750 - loss: 1.970 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3674 - loss: 1.9762\n",
      "Epoch 132/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3750 - loss: 1.982 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3674 - loss: 1.9797\n",
      "Epoch 133/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3750 - loss: 1.962 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3674 - loss: 1.9726\n",
      "Epoch 134/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3750 - loss: 1.978 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3674 - loss: 1.9775\n",
      "Epoch 135/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3438 - loss: 1.983 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3570 - loss: 1.9787\n",
      "Epoch 136/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3750 - loss: 1.977 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.3674 - loss: 1.9761\n",
      "Epoch 137/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3438 - loss: 1.982 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3570 - loss: 1.9778\n",
      "Epoch 138/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3438 - loss: 1.983 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3570 - loss: 1.9776\n",
      "Epoch 139/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3125 - loss: 1.981 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3264 - loss: 1.9766\n",
      "Epoch 140/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.3125 - loss: 1.983 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3264 - loss: 1.9766\n",
      "Epoch 141/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3438 - loss: 1.975 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3368 - loss: 1.9737\n",
      "Epoch 142/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2812 - loss: 1.959 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.2756 - loss: 1.9683\n",
      "Epoch 143/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.2500 - loss: 1.976 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.2449 - loss: 1.9740\n",
      "Epoch 144/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.1875 - loss: 1.981 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.1837 - loss: 1.9762\n",
      "Epoch 145/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.1875 - loss: 1.982 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.1837 - loss: 1.9776\n",
      "Epoch 146/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1875 - loss: 1.977 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1837 - loss: 1.9758\n",
      "Epoch 147/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.1875 - loss: 1.981 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.2039 - loss: 1.9762\n",
      "Epoch 148/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.2188 - loss: 1.980 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.2345 - loss: 1.9744\n",
      "Epoch 149/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.2812 - loss: 1.981 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2958 - loss: 1.9735\n",
      "Epoch 150/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.969 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3674 - loss: 1.9686\n",
      "Epoch 151/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3438 - loss: 1.977 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3570 - loss: 1.9704\n",
      "Epoch 152/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.951 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3674 - loss: 1.9611\n",
      "Epoch 153/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3750 - loss: 1.967 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3674 - loss: 1.9661\n",
      "Epoch 154/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3438 - loss: 1.953 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3368 - loss: 1.9610\n",
      "Epoch 155/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3438 - loss: 1.946 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3368 - loss: 1.9582\n",
      "Epoch 156/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.3438 - loss: 1.951 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3368 - loss: 1.9586\n",
      "Epoch 157/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3438 - loss: 1.970 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3570 - loss: 1.9633\n",
      "Epoch 158/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3750 - loss: 1.960 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.9588\n",
      "Epoch 159/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3438 - loss: 1.943 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3368 - loss: 1.9515\n",
      "Epoch 160/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2500 - loss: 1.955 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2449 - loss: 1.9552\n",
      "Epoch 161/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2188 - loss: 1.963 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2143 - loss: 1.9572\n",
      "Epoch 162/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.1875 - loss: 1.964 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2039 - loss: 1.9571\n",
      "Epoch 163/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 1.942 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2143 - loss: 1.9493\n",
      "Epoch 164/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.1875 - loss: 1.963 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2039 - loss: 1.9560\n",
      "Epoch 165/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.1875 - loss: 1.963 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2039 - loss: 1.9553\n",
      "Epoch 166/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2188 - loss: 1.953 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.2143 - loss: 1.9516\n",
      "Epoch 167/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.1875 - loss: 1.963 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2039 - loss: 1.9540\n",
      "Epoch 168/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 1.951 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2143 - loss: 1.9498\n",
      "Epoch 169/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2188 - loss: 1.954 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2143 - loss: 1.9503\n",
      "Epoch 170/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 1.945 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2143 - loss: 1.9465\n",
      "Epoch 171/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2188 - loss: 1.953 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2143 - loss: 1.9483\n",
      "Epoch 172/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2188 - loss: 1.926 ━━━━━━━━━━━━━━━━━━━━ 0s 97ms/step - accuracy: 0.2143 - loss: 1.9384\n",
      "Epoch 173/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2188 - loss: 1.946 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2143 - loss: 1.9442\n",
      "Epoch 174/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.1875 - loss: 1.956 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2039 - loss: 1.9472\n",
      "Epoch 175/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2188 - loss: 1.951 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2143 - loss: 1.9454\n",
      "Epoch 176/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 1.943 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.2143 - loss: 1.9430\n",
      "Epoch 177/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2188 - loss: 1.927 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2143 - loss: 1.9385\n",
      "Epoch 178/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 1.931 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2143 - loss: 1.9394\n",
      "Epoch 179/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.2188 - loss: 1.953 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 1.9462\n",
      "Epoch 180/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2188 - loss: 1.954 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.2345 - loss: 1.9462\n",
      "Epoch 181/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.3125 - loss: 1.952 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3229 - loss: 1.946 ━━━━━━━━━━━━━━━━━━━━ 0s 122ms/step - accuracy: 0.3264 - loss: 1.9450\n",
      "Epoch 182/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3438 - loss: 1.927 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3368 - loss: 1.9362\n",
      "Epoch 183/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3438 - loss: 1.952 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3570 - loss: 1.9441\n",
      "Epoch 184/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3438 - loss: 1.922 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3368 - loss: 1.9332\n",
      "Epoch 185/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3438 - loss: 1.940 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3368 - loss: 1.9384\n",
      "Epoch 186/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3125 - loss: 1.948 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3264 - loss: 1.9401\n",
      "Epoch 187/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.919 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3674 - loss: 1.9302\n",
      "Epoch 188/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.922 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3674 - loss: 1.9304\n",
      "Epoch 189/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3750 - loss: 1.912 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3674 - loss: 1.9254\n",
      "Epoch 190/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 113ms/step - accuracy: 0.3438 - loss: 1.94 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3368 - loss: 1.9333 \n",
      "Epoch 191/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3438 - loss: 1.916 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3368 - loss: 1.9237\n",
      "Epoch 192/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3125 - loss: 1.939 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3264 - loss: 1.9307\n",
      "Epoch 193/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.2500 - loss: 1.906 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2449 - loss: 1.9187\n",
      "Epoch 194/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 1.913 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 1.9208\n",
      "Epoch 195/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.1875 - loss: 1.936 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.2039 - loss: 1.9281\n",
      "Epoch 196/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2188 - loss: 1.925 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2143 - loss: 1.9242\n",
      "Epoch 197/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 1.930 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2143 - loss: 1.9253\n",
      "Epoch 198/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.2188 - loss: 1.907 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2143 - loss: 1.9167\n",
      "Epoch 199/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2188 - loss: 1.922 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2143 - loss: 1.9211\n",
      "Epoch 200/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 1.905 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 1.9144\n",
      "Epoch 201/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2188 - loss: 1.925 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2143 - loss: 1.9203\n",
      "Epoch 202/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2188 - loss: 1.904 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.2143 - loss: 1.9127\n",
      "Epoch 203/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 1.918 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2143 - loss: 1.9165\n",
      "Epoch 204/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2188 - loss: 1.896 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2143 - loss: 1.9083\n",
      "Epoch 205/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 1.900 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2143 - loss: 1.9086\n",
      "Epoch 206/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.1875 - loss: 1.922 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2039 - loss: 1.9151\n",
      "Epoch 207/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2188 - loss: 1.902 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2143 - loss: 1.9075\n",
      "Epoch 208/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2188 - loss: 1.912 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2143 - loss: 1.9099\n",
      "Epoch 209/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 1.902 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2143 - loss: 1.9057\n",
      "Epoch 210/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2188 - loss: 1.896 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.2143 - loss: 1.9028\n",
      "Epoch 211/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2188 - loss: 1.909 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.2143 - loss: 1.9064\n",
      "Epoch 212/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.2188 - loss: 1.909 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 1.9060\n",
      "Epoch 213/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2500 - loss: 1.909 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.2652 - loss: 1.9054\n",
      "Epoch 214/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3125 - loss: 1.898 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3062 - loss: 1.9014\n",
      "Epoch 215/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3438 - loss: 1.887 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3368 - loss: 1.8971\n",
      "Epoch 216/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3438 - loss: 1.887 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3368 - loss: 1.8967\n",
      "Epoch 217/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.3125 - loss: 1.909 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.3264 - loss: 1.9032\n",
      "Epoch 218/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.3438 - loss: 1.905 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3570 - loss: 1.9007\n",
      "Epoch 219/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3125 - loss: 1.905 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.3264 - loss: 1.8993\n",
      "Epoch 220/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3438 - loss: 1.885 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3368 - loss: 1.8913\n",
      "Epoch 221/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3438 - loss: 1.880 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3368 - loss: 1.8878\n",
      "Epoch 222/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3125 - loss: 1.882 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3062 - loss: 1.8877\n",
      "Epoch 223/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2812 - loss: 1.896 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2756 - loss: 1.8937\n",
      "Epoch 224/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 1.896 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2143 - loss: 1.8939\n",
      "Epoch 225/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.1875 - loss: 1.902 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2039 - loss: 1.8949\n",
      "Epoch 226/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 1.873 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2143 - loss: 1.8840\n",
      "Epoch 227/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2188 - loss: 1.889 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2143 - loss: 1.8874\n",
      "Epoch 228/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.2500 - loss: 1.865 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2449 - loss: 1.8769\n",
      "Epoch 229/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2812 - loss: 1.876 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2756 - loss: 1.8778\n",
      "Epoch 230/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3125 - loss: 1.865 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3062 - loss: 1.8715\n",
      "Epoch 231/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2812 - loss: 1.877 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2958 - loss: 1.8729\n",
      "Epoch 232/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3125 - loss: 1.859 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3078 - loss: 1.863 ━━━━━━━━━━━━━━━━━━━━ 0s 142ms/step - accuracy: 0.3062 - loss: 1.8650\n",
      "Epoch 233/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3438 - loss: 1.870 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3570 - loss: 1.8672\n",
      "Epoch 234/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.4375 - loss: 1.871 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.4489 - loss: 1.8661\n",
      "Epoch 235/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 1.858 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.8610\n",
      "Epoch 236/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3438 - loss: 1.869 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3570 - loss: 1.8637\n",
      "Epoch 237/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3750 - loss: 1.855 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.8581\n",
      "Epoch 238/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3750 - loss: 1.853 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3674 - loss: 1.8562\n",
      "Epoch 239/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3750 - loss: 1.854 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3674 - loss: 1.8559\n",
      "Epoch 240/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.840 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3674 - loss: 1.8505\n",
      "Epoch 241/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3438 - loss: 1.861 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.8564\n",
      "Epoch 242/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3438 - loss: 1.847 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3368 - loss: 1.8501\n",
      "Epoch 243/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3125 - loss: 1.856 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3264 - loss: 1.8507\n",
      "Epoch 244/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3438 - loss: 1.843 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3368 - loss: 1.8440\n",
      "Epoch 245/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3438 - loss: 1.831 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3368 - loss: 1.8373\n",
      "Epoch 246/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3438 - loss: 1.836 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3368 - loss: 1.8363\n",
      "Epoch 247/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3125 - loss: 1.840 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3264 - loss: 1.8355\n",
      "Epoch 248/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3438 - loss: 1.820 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3368 - loss: 1.8265\n",
      "Epoch 249/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3438 - loss: 1.829 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3385 - loss: 1.829 ━━━━━━━━━━━━━━━━━━━━ 0s 116ms/step - accuracy: 0.3368 - loss: 1.8289\n",
      "Epoch 250/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3125 - loss: 1.835 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3264 - loss: 1.8313\n",
      "Epoch 251/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3125 - loss: 1.836 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.3264 - loss: 1.8311\n",
      "Epoch 252/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3438 - loss: 1.821 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3368 - loss: 1.8248\n",
      "Epoch 253/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3438 - loss: 1.813 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.3368 - loss: 1.8183\n",
      "Epoch 254/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3438 - loss: 1.807 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3368 - loss: 1.8131\n",
      "Epoch 255/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3125 - loss: 1.814 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3062 - loss: 1.8155\n",
      "Epoch 256/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.2812 - loss: 1.827 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2958 - loss: 1.8203\n",
      "Epoch 257/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.2812 - loss: 1.824 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2958 - loss: 1.8196\n",
      "Epoch 258/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3125 - loss: 1.814 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.3062 - loss: 1.8146\n",
      "Epoch 259/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.2812 - loss: 1.815 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2958 - loss: 1.8117\n",
      "Epoch 260/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.3438 - loss: 1.785 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3368 - loss: 1.7980\n",
      "Epoch 261/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3125 - loss: 1.807 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.3264 - loss: 1.8032\n",
      "Epoch 262/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3125 - loss: 1.809 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3264 - loss: 1.8023\n",
      "Epoch 263/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.3438 - loss: 1.803 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3368 - loss: 1.8011\n",
      "Epoch 264/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3125 - loss: 1.802 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3062 - loss: 1.8037\n",
      "Epoch 265/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.3125 - loss: 1.796 ━━━━━━━━━━━━━━━━━━━━ 0s 117ms/step - accuracy: 0.3062 - loss: 1.8034\n",
      "Epoch 266/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2812 - loss: 1.820 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2958 - loss: 1.8111\n",
      "Epoch 267/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.3125 - loss: 1.810 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3062 - loss: 1.8068\n",
      "Epoch 268/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2812 - loss: 1.809 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2958 - loss: 1.8048\n",
      "Epoch 269/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3125 - loss: 1.781 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.3062 - loss: 1.7917\n",
      "Epoch 270/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3125 - loss: 1.794 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3062 - loss: 1.7908\n",
      "Epoch 271/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2812 - loss: 1.790 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2958 - loss: 1.7850\n",
      "Epoch 272/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3438 - loss: 1.766 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3368 - loss: 1.7727\n",
      "Epoch 273/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.3438 - loss: 1.764 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.3368 - loss: 1.7668\n",
      "Epoch 274/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.3750 - loss: 1.768 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3674 - loss: 1.7646\n",
      "Epoch 275/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.5000 - loss: 1.763 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.4899 - loss: 1.7626\n",
      "Epoch 276/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.4062 - loss: 1.772 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.4182 - loss: 1.7666\n",
      "Epoch 277/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.4375 - loss: 1.759 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.4287 - loss: 1.7611\n",
      "Epoch 278/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.4062 - loss: 1.765 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.4182 - loss: 1.7611\n",
      "Epoch 279/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.4062 - loss: 1.765 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.4182 - loss: 1.7585\n",
      "Epoch 280/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.4062 - loss: 1.761 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.4182 - loss: 1.7541\n",
      "Epoch 281/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.4375 - loss: 1.724 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.4287 - loss: 1.7394\n",
      "Epoch 282/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.4375 - loss: 1.719 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4287 - loss: 1.7340\n",
      "Epoch 283/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.4062 - loss: 1.747 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.4182 - loss: 1.7399\n",
      "Epoch 284/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4062 - loss: 1.738 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.4182 - loss: 1.7349\n",
      "Epoch 285/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.4375 - loss: 1.730 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4287 - loss: 1.7308\n",
      "Epoch 286/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.4688 - loss: 1.711 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.4593 - loss: 1.7230\n",
      "Epoch 287/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.4688 - loss: 1.734 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.4795 - loss: 1.7305\n",
      "Epoch 288/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5000 - loss: 1.729 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4899 - loss: 1.7287\n",
      "Epoch 289/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.4688 - loss: 1.731 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.4593 - loss: 1.7289\n",
      "Epoch 290/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.4375 - loss: 1.720 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.4287 - loss: 1.7256\n",
      "Epoch 291/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4062 - loss: 1.732 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.4182 - loss: 1.7265\n",
      "Epoch 292/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.4062 - loss: 1.721 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3980 - loss: 1.7182\n",
      "Epoch 293/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.4062 - loss: 1.723 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4182 - loss: 1.7157\n",
      "Epoch 294/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.4062 - loss: 1.715 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.4182 - loss: 1.7095\n",
      "Epoch 295/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.4062 - loss: 1.707 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.4182 - loss: 1.7041\n",
      "Epoch 296/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.4375 - loss: 1.701 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.4287 - loss: 1.6997\n",
      "Epoch 297/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4688 - loss: 1.675 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.4593 - loss: 1.6883\n",
      "Epoch 298/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.5000 - loss: 1.695 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.4899 - loss: 1.6921\n",
      "Epoch 299/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.4688 - loss: 1.699 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.4795 - loss: 1.6923\n",
      "Epoch 300/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5312 - loss: 1.673 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5205 - loss: 1.6850\n",
      "Epoch 301/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.5312 - loss: 1.702 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.5407 - loss: 1.6979\n",
      "Epoch 302/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5625 - loss: 1.707 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5713 - loss: 1.7004\n",
      "Epoch 303/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5938 - loss: 1.701 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.6020 - loss: 1.6980\n",
      "Epoch 304/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5938 - loss: 1.700 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.6020 - loss: 1.6963\n",
      "Epoch 305/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5938 - loss: 1.700 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.6020 - loss: 1.6916\n",
      "Epoch 306/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.5938 - loss: 1.689 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6020 - loss: 1.6828\n",
      "Epoch 307/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6250 - loss: 1.655 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6124 - loss: 1.6662\n",
      "Epoch 308/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.5938 - loss: 1.673 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6020 - loss: 1.6667\n",
      "Epoch 309/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.5938 - loss: 1.664 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6020 - loss: 1.6577\n",
      "Epoch 310/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.6250 - loss: 1.651 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6326 - loss: 1.6465\n",
      "Epoch 311/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.644 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5713 - loss: 1.6392\n",
      "Epoch 312/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5625 - loss: 1.629 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5511 - loss: 1.6304\n",
      "Epoch 313/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.4688 - loss: 1.634 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4593 - loss: 1.6311\n",
      "Epoch 314/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.4375 - loss: 1.643 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.4489 - loss: 1.6336\n",
      "Epoch 315/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.4062 - loss: 1.634 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3980 - loss: 1.6304\n",
      "Epoch 316/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.4062 - loss: 1.639 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.4182 - loss: 1.6290\n",
      "Epoch 317/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3750 - loss: 1.630 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3876 - loss: 1.6207\n",
      "Epoch 318/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.617 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3674 - loss: 1.6132\n",
      "Epoch 319/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3438 - loss: 1.582 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3368 - loss: 1.5994\n",
      "Epoch 320/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.596 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3674 - loss: 1.6033\n",
      "Epoch 321/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.578 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3674 - loss: 1.5946\n",
      "Epoch 322/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3750 - loss: 1.592 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3674 - loss: 1.5969\n",
      "Epoch 323/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.3438 - loss: 1.597 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.3368 - loss: 1.5990\n",
      "Epoch 324/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2812 - loss: 1.601 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.2756 - loss: 1.6011\n",
      "Epoch 325/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2812 - loss: 1.603 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2756 - loss: 1.5994\n",
      "Epoch 326/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3125 - loss: 1.594 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3062 - loss: 1.5903\n",
      "Epoch 327/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.4062 - loss: 1.561 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3980 - loss: 1.5741\n",
      "Epoch 328/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.4375 - loss: 1.578 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.4287 - loss: 1.5752\n",
      "Epoch 329/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.4062 - loss: 1.581 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.4182 - loss: 1.5756\n",
      "Epoch 330/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.4375 - loss: 1.579 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.4489 - loss: 1.5746\n",
      "Epoch 331/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.4688 - loss: 1.554 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.4593 - loss: 1.5637\n",
      "Epoch 332/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.4375 - loss: 1.578 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.4489 - loss: 1.5700\n",
      "Epoch 333/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.4062 - loss: 1.579 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.4182 - loss: 1.5718\n",
      "Epoch 334/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.4375 - loss: 1.576 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.4489 - loss: 1.5709\n",
      "Epoch 335/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5000 - loss: 1.566 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4899 - loss: 1.5672\n",
      "Epoch 336/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5000 - loss: 1.553 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4899 - loss: 1.5562\n",
      "Epoch 337/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.515 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5511 - loss: 1.5307\n",
      "Epoch 338/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.6250 - loss: 1.509 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6124 - loss: 1.5193\n",
      "Epoch 339/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5625 - loss: 1.505 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5511 - loss: 1.5125\n",
      "Epoch 340/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5312 - loss: 1.524 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.5407 - loss: 1.5164\n",
      "Epoch 341/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5312 - loss: 1.516 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.5407 - loss: 1.5115\n",
      "Epoch 342/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.5625 - loss: 1.514 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5713 - loss: 1.5084\n",
      "Epoch 343/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5938 - loss: 1.478 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5818 - loss: 1.4938\n",
      "Epoch 344/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.510 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5713 - loss: 1.5023\n",
      "Epoch 345/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5625 - loss: 1.490 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5511 - loss: 1.4929\n",
      "Epoch 346/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.5000 - loss: 1.501 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5101 - loss: 1.4933\n",
      "Epoch 347/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5000 - loss: 1.487 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.5101 - loss: 1.4857\n",
      "Epoch 348/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5000 - loss: 1.491 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5101 - loss: 1.4837\n",
      "Epoch 349/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.5312 - loss: 1.474 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5205 - loss: 1.4760\n",
      "Epoch 350/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5312 - loss: 1.459 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5205 - loss: 1.4689\n",
      "Epoch 351/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.5312 - loss: 1.466 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5205 - loss: 1.4679\n",
      "Epoch 352/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5000 - loss: 1.477 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5101 - loss: 1.4680\n",
      "Epoch 353/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5000 - loss: 1.471 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.5101 - loss: 1.4634\n",
      "Epoch 354/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.5000 - loss: 1.461 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5101 - loss: 1.4571\n",
      "Epoch 355/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5312 - loss: 1.453 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5407 - loss: 1.4527\n",
      "Epoch 356/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5625 - loss: 1.420 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5511 - loss: 1.4389\n",
      "Epoch 357/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.5000 - loss: 1.451 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5101 - loss: 1.4456\n",
      "Epoch 358/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.5000 - loss: 1.433 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.4899 - loss: 1.4375\n",
      "Epoch 359/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5000 - loss: 1.433 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.4899 - loss: 1.4345\n",
      "Epoch 360/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.5000 - loss: 1.446 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5101 - loss: 1.4360\n",
      "Epoch 361/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5312 - loss: 1.428 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5205 - loss: 1.4274\n",
      "Epoch 362/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5312 - loss: 1.423 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.5205 - loss: 1.4236\n",
      "Epoch 363/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5000 - loss: 1.434 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.5101 - loss: 1.4261\n",
      "Epoch 364/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5312 - loss: 1.389 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5205 - loss: 1.4089\n",
      "Epoch 365/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5625 - loss: 1.381 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5511 - loss: 1.4030\n",
      "Epoch 366/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5312 - loss: 1.420 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5407 - loss: 1.4126\n",
      "Epoch 367/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.5312 - loss: 1.408 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5407 - loss: 1.4064\n",
      "Epoch 368/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.374 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5511 - loss: 1.3939\n",
      "Epoch 369/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5312 - loss: 1.419 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.5407 - loss: 1.4076\n",
      "Epoch 370/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5625 - loss: 1.397 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5511 - loss: 1.3990\n",
      "Epoch 371/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.369 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5511 - loss: 1.3874\n",
      "Epoch 372/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.395 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5511 - loss: 1.3928\n",
      "Epoch 373/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5625 - loss: 1.382 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.5511 - loss: 1.3837\n",
      "Epoch 374/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.371 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.5511 - loss: 1.3742\n",
      "Epoch 375/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.7500 - loss: 1.338 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.7348 - loss: 1.3597\n",
      "Epoch 376/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.6875 - loss: 1.372 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.6938 - loss: 1.3715\n",
      "Epoch 377/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.6562 - loss: 1.379 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6632 - loss: 1.3783\n",
      "Epoch 378/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.6250 - loss: 1.391 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.6326 - loss: 1.3897\n",
      "Epoch 379/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.6562 - loss: 1.389 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.6430 - loss: 1.3939\n",
      "Epoch 380/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.6250 - loss: 1.402 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.6326 - loss: 1.3978\n",
      "Epoch 381/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.6250 - loss: 1.399 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.6326 - loss: 1.3965\n",
      "Epoch 382/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6250 - loss: 1.399 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6124 - loss: 1.3971\n",
      "Epoch 383/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.6250 - loss: 1.390 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6326 - loss: 1.3872\n",
      "Epoch 384/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6562 - loss: 1.360 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.6430 - loss: 1.3645\n",
      "Epoch 385/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6562 - loss: 1.353 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.6430 - loss: 1.3510\n",
      "Epoch 386/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.6250 - loss: 1.344 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6326 - loss: 1.3404\n",
      "Epoch 387/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6562 - loss: 1.339 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6632 - loss: 1.3336\n",
      "Epoch 388/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6875 - loss: 1.338 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6938 - loss: 1.3368\n",
      "Epoch 389/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.6875 - loss: 1.348 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6736 - loss: 1.3433\n",
      "Epoch 390/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6875 - loss: 1.309 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6736 - loss: 1.3308\n",
      "Epoch 391/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6562 - loss: 1.354 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6632 - loss: 1.3434\n",
      "Epoch 392/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.7188 - loss: 1.297 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.7042 - loss: 1.3181\n",
      "Epoch 393/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6875 - loss: 1.332 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.6938 - loss: 1.3204\n",
      "Epoch 394/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.7188 - loss: 1.320 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.7244 - loss: 1.3078\n",
      "Epoch 395/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.7500 - loss: 1.266 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.7348 - loss: 1.2849\n",
      "Epoch 396/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6875 - loss: 1.310 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6938 - loss: 1.2972\n",
      "Epoch 397/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6875 - loss: 1.287 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6736 - loss: 1.2896\n",
      "Epoch 398/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.6250 - loss: 1.294 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6326 - loss: 1.2911\n",
      "Epoch 399/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.6562 - loss: 1.310 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.6632 - loss: 1.2952\n",
      "Epoch 400/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.6250 - loss: 1.297 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6326 - loss: 1.2899\n",
      "Epoch 401/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5625 - loss: 1.280 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5511 - loss: 1.2819\n",
      "Epoch 402/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.5625 - loss: 1.268 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.5511 - loss: 1.2712\n",
      "Epoch 403/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.6562 - loss: 1.258 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.6632 - loss: 1.2582\n",
      "Epoch 404/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.7500 - loss: 1.246 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.7348 - loss: 1.2525\n",
      "Epoch 405/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.7188 - loss: 1.243 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.7042 - loss: 1.2679\n",
      "Epoch 406/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.6562 - loss: 1.330 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.6632 - loss: 1.3164\n",
      "Epoch 407/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.6562 - loss: 1.321 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.6632 - loss: 1.3190\n",
      "Epoch 408/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6562 - loss: 1.306 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6632 - loss: 1.3026\n",
      "Epoch 409/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.7500 - loss: 1.236 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.7348 - loss: 1.2583\n",
      "Epoch 410/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6250 - loss: 1.249 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6326 - loss: 1.2449\n",
      "Epoch 411/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5938 - loss: 1.218 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5818 - loss: 1.2276\n",
      "Epoch 412/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.249 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5713 - loss: 1.2341\n",
      "Epoch 413/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5938 - loss: 1.208 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5818 - loss: 1.2179\n",
      "Epoch 414/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5625 - loss: 1.240 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5713 - loss: 1.2248\n",
      "Epoch 415/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.5938 - loss: 1.184 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5818 - loss: 1.2033\n",
      "Epoch 416/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5938 - loss: 1.214 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.6020 - loss: 1.2114\n",
      "Epoch 417/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6250 - loss: 1.201 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.6124 - loss: 1.2055\n",
      "Epoch 418/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5938 - loss: 1.214 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.6020 - loss: 1.2106\n",
      "Epoch 419/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5938 - loss: 1.238 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6020 - loss: 1.2218\n",
      "Epoch 420/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.7188 - loss: 1.228 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.7244 - loss: 1.2220\n",
      "Epoch 421/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.7188 - loss: 1.219 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.7244 - loss: 1.2178\n",
      "Epoch 422/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6250 - loss: 1.212 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.6326 - loss: 1.2078\n",
      "Epoch 423/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5938 - loss: 1.198 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.6020 - loss: 1.1941\n",
      "Epoch 424/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5625 - loss: 1.186 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.5713 - loss: 1.1836\n",
      "Epoch 425/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.5625 - loss: 1.199 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5713 - loss: 1.1840\n",
      "Epoch 426/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5625 - loss: 1.197 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.5713 - loss: 1.1816\n",
      "Epoch 427/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.5625 - loss: 1.182 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5713 - loss: 1.1759\n",
      "Epoch 428/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5938 - loss: 1.167 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.5818 - loss: 1.1709\n",
      "Epoch 429/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5625 - loss: 1.176 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5713 - loss: 1.1732\n",
      "Epoch 430/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step - accuracy: 0.5938 - loss: 1.163 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5818 - loss: 1.1660\n",
      "Epoch 431/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5938 - loss: 1.133 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.5818 - loss: 1.1521\n",
      "Epoch 432/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5625 - loss: 1.159 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5713 - loss: 1.1568\n",
      "Epoch 433/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.179 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.5713 - loss: 1.1619\n",
      "Epoch 434/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.5625 - loss: 1.166 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5713 - loss: 1.1584\n",
      "Epoch 435/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5625 - loss: 1.159 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5713 - loss: 1.1555\n",
      "Epoch 436/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5938 - loss: 1.130 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.5818 - loss: 1.1458\n",
      "Epoch 437/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5625 - loss: 1.154 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.5713 - loss: 1.1555\n",
      "Epoch 438/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5938 - loss: 1.139 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5818 - loss: 1.1460\n",
      "Epoch 439/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5625 - loss: 1.147 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5713 - loss: 1.1409\n",
      "Epoch 440/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5625 - loss: 1.141 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5713 - loss: 1.1335\n",
      "Epoch 441/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5625 - loss: 1.131 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.5713 - loss: 1.1269\n",
      "Epoch 442/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.6250 - loss: 1.086 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6124 - loss: 1.1106\n",
      "Epoch 443/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.5938 - loss: 1.132 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6020 - loss: 1.1265\n",
      "Epoch 444/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6250 - loss: 1.100 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6124 - loss: 1.1171\n",
      "Epoch 445/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.5938 - loss: 1.131 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.6020 - loss: 1.1263\n",
      "Epoch 446/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.5938 - loss: 1.116 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.6020 - loss: 1.1185\n",
      "Epoch 447/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.6250 - loss: 1.072 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.6124 - loss: 1.0967\n",
      "Epoch 448/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5938 - loss: 1.070 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5818 - loss: 1.0878\n",
      "Epoch 449/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step - accuracy: 0.5938 - loss: 1.061 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5818 - loss: 1.0831\n",
      "Epoch 450/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.5938 - loss: 1.080 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.5818 - loss: 1.0957\n",
      "Epoch 451/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.5938 - loss: 1.108 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5818 - loss: 1.1153\n",
      "Epoch 452/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 1.141 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5713 - loss: 1.1338\n",
      "Epoch 453/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5625 - loss: 1.163 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5713 - loss: 1.1455\n",
      "Epoch 454/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.5625 - loss: 1.150 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5713 - loss: 1.1433\n",
      "Epoch 455/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5938 - loss: 1.114 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.5818 - loss: 1.1265\n",
      "Epoch 456/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5625 - loss: 1.128 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5713 - loss: 1.1217\n",
      "Epoch 457/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5938 - loss: 1.093 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5818 - loss: 1.0998\n",
      "Epoch 458/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5625 - loss: 1.111 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.5713 - loss: 1.0942\n",
      "Epoch 459/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5625 - loss: 1.086 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.5713 - loss: 1.0768\n",
      "Epoch 460/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5625 - loss: 1.062 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.5713 - loss: 1.0645\n",
      "Epoch 461/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5625 - loss: 1.085 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5713 - loss: 1.0684\n",
      "Epoch 462/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5625 - loss: 1.052 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.5713 - loss: 1.0541\n",
      "Epoch 463/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5625 - loss: 1.059 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5713 - loss: 1.0533\n",
      "Epoch 464/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5938 - loss: 1.029 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.5818 - loss: 1.0411\n",
      "Epoch 465/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5625 - loss: 1.055 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5713 - loss: 1.0488\n",
      "Epoch 466/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.5625 - loss: 1.053 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.5713 - loss: 1.0466\n",
      "Epoch 467/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5625 - loss: 1.053 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.5713 - loss: 1.0439\n",
      "Epoch 468/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.5625 - loss: 1.05 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5713 - loss: 1.0440 \n",
      "Epoch 469/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.5938 - loss: 1.004 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5818 - loss: 1.0289\n",
      "Epoch 470/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5938 - loss: 1.010 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5818 - loss: 1.0320\n",
      "Epoch 471/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5625 - loss: 1.053 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5713 - loss: 1.0471\n",
      "Epoch 472/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5625 - loss: 1.065 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.5713 - loss: 1.0531\n",
      "Epoch 473/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5938 - loss: 1.034 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5818 - loss: 1.0482\n",
      "Epoch 474/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5938 - loss: 1.039 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5818 - loss: 1.0520\n",
      "Epoch 475/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5938 - loss: 1.039 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.5818 - loss: 1.0481\n",
      "Epoch 476/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.5625 - loss: 1.063 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5713 - loss: 1.0474\n",
      "Epoch 477/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5625 - loss: 1.021 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5713 - loss: 1.0236\n",
      "Epoch 478/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5625 - loss: 1.036 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5713 - loss: 1.0224\n",
      "Epoch 479/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/step - accuracy: 0.5938 - loss: 0.984 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.5818 - loss: 1.0056\n",
      "Epoch 480/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.5625 - loss: 1.03 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5713 - loss: 1.0247 \n",
      "Epoch 481/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.5625 - loss: 1.013 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5713 - loss: 1.0166\n",
      "Epoch 482/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5938 - loss: 0.999 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5818 - loss: 1.0051\n",
      "Epoch 483/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5938 - loss: 0.974 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5818 - loss: 0.9895\n",
      "Epoch 484/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5625 - loss: 1.012 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.5713 - loss: 0.9973\n",
      "Epoch 485/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5625 - loss: 0.999 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5713 - loss: 0.9901\n",
      "Epoch 486/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.6250 - loss: 0.971 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6124 - loss: 0.9776\n",
      "Epoch 487/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5938 - loss: 0.992 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6020 - loss: 0.9824\n",
      "Epoch 488/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.7188 - loss: 0.968 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.7244 - loss: 0.9723\n",
      "Epoch 489/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.7188 - loss: 0.987 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.7244 - loss: 0.9764\n",
      "Epoch 490/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.7188 - loss: 0.990 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.7244 - loss: 0.9748\n",
      "Epoch 491/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.7188 - loss: 0.978 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.7244 - loss: 0.9687\n",
      "Epoch 492/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.7188 - loss: 0.964 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.7230 - loss: 0.963 ━━━━━━━━━━━━━━━━━━━━ 0s 134ms/step - accuracy: 0.7244 - loss: 0.9633\n",
      "Epoch 493/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6875 - loss: 0.956 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6736 - loss: 0.9593\n",
      "Epoch 494/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6875 - loss: 0.972 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6938 - loss: 0.9622\n",
      "Epoch 495/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.7188 - loss: 0.949 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.7244 - loss: 0.9519\n",
      "Epoch 496/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6875 - loss: 0.973 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6938 - loss: 0.9581\n",
      "Epoch 497/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.7188 - loss: 0.923 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.7042 - loss: 0.9398\n",
      "Epoch 498/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6875 - loss: 0.960 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.6938 - loss: 0.9503\n",
      "Epoch 499/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.7188 - loss: 0.960 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.7244 - loss: 0.9494\n",
      "Epoch 500/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7500 - loss: 0.909 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.7348 - loss: 0.9325\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "epochs = 500\n",
    "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "213939e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# to save the trained model\n",
    "model.save(\"chat_model.h5\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# to save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# to save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2dcfbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hii\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 111ms/st ━━━━━━━━━━━━━━━━━━━━ 0s 167ms/step\n",
      "ChatBot: Hi there\n",
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " An virtual assistant chatbot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step\n",
      "ChatBot: Hi there\n",
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quit\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model.h5')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d43db49",
   "metadata": {},
   "source": [
    "# chatbot-8 GUI based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35029fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Win 10\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Win 10\\AppData\\Local\\Temp\\ipykernel_12948\\1880169308.py\", line 81, in send\n",
      "    res = chatbot_response(msg)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Win 10\\AppData\\Local\\Temp\\ipykernel_12948\\1880169308.py\", line 62, in chatbot_response\n",
      "    ints = predict_class(msg, model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Win 10\\AppData\\Local\\Temp\\ipykernel_12948\\1880169308.py\", line 42, in predict_class\n",
      "    res = model.predict(np.array([p]))[0]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Win 10\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Win 10\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 276, in _adjust_input_rank\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "Invalid input shape for input Tensor(\"sequential_1_1/Cast:0\", shape=(1, 88), dtype=float32). Expected shape (None, None, 88), but input has incompatible shape (1, 88)\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 88), dtype=int32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "  • kwargs=<class 'inspect._empty'>\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Win 10\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Win 10\\AppData\\Local\\Temp\\ipykernel_12948\\1880169308.py\", line 81, in send\n",
      "    res = chatbot_response(msg)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Win 10\\AppData\\Local\\Temp\\ipykernel_12948\\1880169308.py\", line 62, in chatbot_response\n",
      "    ints = predict_class(msg, model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Win 10\\AppData\\Local\\Temp\\ipykernel_12948\\1880169308.py\", line 42, in predict_class\n",
      "    res = model.predict(np.array([p]))[0]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Win 10\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\Win 10\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 276, in _adjust_input_rank\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "Invalid input shape for input Tensor(\"sequential_1_1/Cast:0\", shape=(1, 88), dtype=float32). Expected shape (None, None, 88), but input has incompatible shape (1, 88)\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 88), dtype=int32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "  • kwargs=<class 'inspect._empty'>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('chatbot_model.h5')\n",
    "import json\n",
    "import random\n",
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res\n",
    "\n",
    "\n",
    "#Creating GUI with tkinter\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "\n",
    "\n",
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "    \n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"shaheel: \" + res + '\\n\\n')\n",
    "            \n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    " \n",
    "\n",
    "base = Tk()\n",
    "base.title(\"Hello\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "#Create Chat window\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
    "\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "#Bind scrollbar to Chat window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "#Create Button to send message\n",
    "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                    command= send )\n",
    "\n",
    "#Create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "#EntryBox.bind(\"<Return>\", send)\n",
    "\n",
    "\n",
    "#Place all components on the screen\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)\n",
    "\n",
    "base.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "145d792c-7b02-4666-86d9-247e972b51c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H, or h, is the eighth letter of the Latin alphabet, used in the modern English alphabet, including the alphabets of other western European languages and others worldwide. Its name in English is aitch (pronounced  , plural aitches), or regionally haitch (pronounced , plural haitches).\n",
      "\n",
      "\n",
      "== Name ==\n",
      "\n",
      "\n",
      "=== English ===\n",
      "For most English speakers, the name for the letter is pronounced as  and spelled \"aitch\" or occasionally \"eitch\".\n"
     ]
    }
   ],
   "source": [
    "# Python package supporting common text-to-speech engines\n",
    "import pyttsx3\n",
    "  \n",
    "# For understanding speech\n",
    "import speech_recognition as sr\n",
    "  \n",
    "# For fetching the answers to computational queries\n",
    "import wolframalpha\n",
    "  \n",
    "# for fetching wikipedia articles\n",
    "import wikipedia\n",
    "# Function to search the query that is either entered or spoken by user\n",
    "def search(query):\n",
    "      \n",
    "    # try is used for searching with wolframAlpha\n",
    "    try:\n",
    "          \n",
    "        # Generate your App ID from WolframAlpha \n",
    "        app_id = \"Your WolframAlpha App ID here\"\n",
    "        client = wolframalpha.Client(ULVYEJ-KXH8TGLUR9)\n",
    "        res = client.query(query)\n",
    "        answer = next(res.results).text\n",
    "        print(answer)\n",
    "        SpeakText(\"Your answer is \" + answer)\n",
    "          \n",
    "    # If the query cannot be searched using WolframAlpha then it is searched in wikipedia\n",
    "    except:\n",
    "          \n",
    "        query = query.split(' ') \n",
    "        query = \" \".join(query[0:])\n",
    "          \n",
    "        SpeakText(\"shaheel Robo is searching for \" + query)\n",
    "        print(wikipedia.summary(query, sentences = 3))\n",
    "        SpeakText(wikipedia.summary(query, \n",
    "                                      sentences = 3))\n",
    "        # Function to convert text to \n",
    "# speech \n",
    "def SpeakText(command): \n",
    "        \n",
    "    # Initialize the engine \n",
    "    engine = pyttsx3.init() \n",
    "    engine.say(command)  \n",
    "    engine.runAndWait()\n",
    "\n",
    "# Driver's code\n",
    "# input query from the user by \n",
    "# typing or by voice\n",
    "query = input()\n",
    "query = query.lower()\n",
    "  \n",
    "# if query is blank then user \n",
    "# is prompted to speak something.\n",
    "if query == '': \n",
    "    r = sr.Recognizer()\n",
    "  \n",
    "    # uses the default microphone\n",
    "    # as the source to record voice\n",
    "    with sr.Microphone() as source:  \n",
    "        print(\"Say Something \")\n",
    "  \n",
    "        # reduces the background disturbances\n",
    "        # and noise for 2 seconds\n",
    "        r.adjust_for_ambient_noise(source, 2)  \n",
    "          \n",
    "        # listening to source\n",
    "        audio = r.listen(source)  \n",
    "    try:\n",
    "        speech = r.recognize_google(audio)\n",
    "        search(speech)\n",
    "  \n",
    "    # Handling Exceptions if speech \n",
    "    # is not understood.\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not \\\n",
    "        understand audio\")\n",
    "  \n",
    "    # Couldn't handle requests, occurs \n",
    "    # mainly because of network errors\n",
    "    except sr.RequestError as e:  \n",
    "        print(\"Could not request results from Google \\\n",
    "        Speech Recognition service;{0}\".format(e))\n",
    "else:\n",
    "    search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290a357-89f4-4df9-b5eb-ef89d178982a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
